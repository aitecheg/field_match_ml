{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub\n",
    "tensorflow_hub.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import boto3\n",
    "import tensorflow as tf\n",
    "from util import vectorize_demo_data, custom_stacked_bidirectional_GRU_layer, CustomElmoEmbeddingLayer, ManDistanceLayer, kinitializer\n",
    "os.chdir(\"/home/elsallab/Work/cod/siamese_text/repo/models\")\n",
    "state_size = 300\n",
    "staked_layers = 3\n",
    "\n",
    "siamese = tf.keras.models.load_model('/home/elsallab/Work/cod/siamese_text/repo/models/elmo.h5',\n",
    "                                     custom_objects={'_custom_stacked_bidirectional_GRU': \n",
    "                                                     custom_stacked_bidirectional_GRU_layer(state_size, staked_layers), \n",
    "                                                     \"CustomElmoEmbeddingLayer\": CustomElmoEmbeddingLayer, \n",
    "                                                     \"ManDistanceLayer\": ManDistanceLayer})\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload model\n",
    "\n",
    "siamese.save_weights('/home/elsallab/Work/cod/siamese_text/repo/models/w8s.h5')\n",
    "open('/home/elsallab/Work/cod/siamese_text/repo/models/w8s.arch', \"w\").write(siamese.to_json())\n",
    "\n",
    "!tar -zcvf elmo_1.h5.tar.gz w8s.h5 w8s.arch\n",
    "\n",
    "s3 = boto3.resource('s3', aws_access_key_id='AKIAJPFSLVGQQGDS7U7A', aws_secret_access_key='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')\n",
    "\n",
    "def upload_file(s3, bucket, bin_data, s3_path_to_file):\n",
    "    # s3.Bucket(bucket).upload_file(local_path_to_file, s3_path_to_file)\n",
    "    s3.Object(bucket_name=bucket, key=s3_path_to_file).put(Body=bin_data)  ## Body = some binary data protocol=2\n",
    "\n",
    "upload_file(s3, \"sagemaker-field-matching\", open(\"elmo_1.h5.tar.gz\", \"rb\"), \"elmo_1.h5.tar.gz\")  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import string\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "subprocess.call([sys.executable, '-m', 'pip', 'install', '-U', 'opencv-python'])\n",
    "subprocess.call([sys.executable, '-m', 'pip', 'install', '-U', 'pillow'])\n",
    "subprocess.call([sys.executable, '-m', 'pip', 'install', '-U', 'tensorflow'])\n",
    "subprocess.call([sys.executable, '-m', 'pip', 'install', '-U', 'tensorflow-hub'])\n",
    "\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "from tensorflow.python.keras.engine.saving import model_from_json\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.python.layers.base import Layer\n",
    "from tensorflow.python.ops.rnn_cell_impl import MultiRNNCell\n",
    "\n",
    "\n",
    "class CustomElmoEmbeddingLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.dimensions = 1024\n",
    "        self.trainable = True\n",
    "        self.elmo = None\n",
    "        self.result = None\n",
    "        super(CustomElmoEmbeddingLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.elmo = hub.Module('https://tfhub.dev/google/elmo/2', trainable=False,\n",
    "                               )\n",
    "\n",
    "        self._trainable_weights += self.elmo._graph._collections[\"variables\"]  # building multiple times will accumulate the weights\n",
    "        print(\"added \", len(self._trainable_weights), \"variables\")\n",
    "        super(CustomElmoEmbeddingLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, tokenized, mask=None):\n",
    "        tokens_input, tokens_length = tokenized\n",
    "\n",
    "        self.result = self.elmo(inputs={\n",
    "            \"tokens\": tokens_input,\n",
    "            \"sequence_len\": tokens_length[:, 0]\n",
    "        },\n",
    "            as_dict=True,\n",
    "            signature='tokens',\n",
    "        )['elmo']  # [batch_size, max_length, 1024]\n",
    "        return self.result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return K.int_shape(self.result)\n",
    "\n",
    "\n",
    "def custom_stacked_bidirectional_GRU_layer(state_size, staked_layers):\n",
    "    class _custom_stacked_bidirectional_GRU(Layer):\n",
    "        \"\"\"\n",
    "        Keras Custom Layer that calculates Manhattan Distance.\n",
    "        \"\"\"\n",
    "\n",
    "        # initialize the layer, No need to include inputs parameter!\n",
    "        def __init__(self, state_size=state_size, staked_layers=staked_layers, **kwargs):\n",
    "            self.final_state = None\n",
    "            self.fw_state_tuple_multicell = None\n",
    "            self.bw_state_tuple_multicell = None\n",
    "            self.state_size = state_size\n",
    "            self.staked_layers = staked_layers\n",
    "            self.registered_weights = False\n",
    "            super(_custom_stacked_bidirectional_GRU, self).__init__(**kwargs)\n",
    "\n",
    "        # input_shape will automatic collect input shapes to build layer\n",
    "        def build(self, input_shape):\n",
    "            \"\"\"\n",
    "            this is where you will define your weights.\n",
    "            you also have to add the weights manually\n",
    "            This method must set self.built = True at the end, which can be done by calling super([Layer], self).build().\n",
    "\n",
    "            if you leave this with no added internal state use lambda function instead\n",
    "            \"\"\"\n",
    "\n",
    "            self.fw_state_tuple_multicell = MultiRNNCell([tf.contrib.rnn.GRUCell(self.state_size) for _ in range(self.staked_layers)], state_is_tuple=False)\n",
    "            self.bw_state_tuple_multicell = MultiRNNCell([tf.contrib.rnn.GRUCell(self.state_size) for _ in range(self.staked_layers)], state_is_tuple=False)\n",
    "\n",
    "            # self.fw_state_tuple_multicell_d = DropoutWrapper((self.fw_state_tuple_multicell), output_keep_prob=.8, state_keep_prob=.8)\n",
    "            # self.bw_state_tuple_multicell_d = DropoutWrapper((self.bw_state_tuple_multicell), output_keep_prob=.8, state_keep_prob=.8)\n",
    "\n",
    "            # not yet built\n",
    "            # self._trainable_weights += ??\n",
    "            # self._non_trainable_weights += ??\n",
    "\n",
    "            super(_custom_stacked_bidirectional_GRU, self).build(input_shape)\n",
    "\n",
    "        # This is where the layer's logic lives.\n",
    "        def call(self, args, **kwargs):\n",
    "            \"\"\"\n",
    "            this is where the layer's logic lives. Unless you want your layer to support masking,\n",
    "             you only have to care about the first argument passed to call: the input tensor.\n",
    "            \"\"\"\n",
    "            inputs, sequence_length = args\n",
    "\n",
    "            _, (final_state_fw, final_state_bw) = \\\n",
    "                tf.nn.bidirectional_dynamic_rnn(cell_fw=self.fw_state_tuple_multicell,\n",
    "                                                cell_bw=self.bw_state_tuple_multicell,\n",
    "                                                inputs=inputs,\n",
    "                                                sequence_length=sequence_length[:, 0],\n",
    "                                                dtype=tf.float32,\n",
    "                                                )\n",
    "            if not self.registered_weights:\n",
    "                self._trainable_weights += self.fw_state_tuple_multicell.trainable_weights\n",
    "                self._trainable_weights += self.bw_state_tuple_multicell.trainable_weights\n",
    "\n",
    "                self.registered_weights = True\n",
    "\n",
    "            self.final_state = K.concatenate([final_state_fw, final_state_bw])\n",
    "\n",
    "            return self.final_state\n",
    "\n",
    "        # return output shape\n",
    "        def compute_output_shape(self, input_shape):\n",
    "            \"\"\"in case your layer modifies the shape of its input, you should sapecify here the shape transformation logic.\n",
    "             This allows Keras to do automatic shape inference.\"\"\"\n",
    "            return K.int_shape(self.final_state)\n",
    "\n",
    "    return _custom_stacked_bidirectional_GRU()\n",
    "\n",
    "\n",
    "class ManDistanceLayer(Layer):\n",
    "    \"\"\"\n",
    "    Keras Custom Layer that calculates Manhattan Distance.\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize the layer, No need to include inputs parameter!\n",
    "    def __init__(self, **kwargs):\n",
    "        self.result = None\n",
    "        super(ManDistanceLayer, self).__init__(**kwargs)\n",
    "\n",
    "    # input_shape will automatic collect input shapes to build layer\n",
    "    def build(self, input_shape):\n",
    "        super(ManDistanceLayer, self).build(input_shape)\n",
    "\n",
    "    # This is where the layer's logic lives.\n",
    "    def call(self, x, **kwargs):\n",
    "        self.result = K.exp(-K.sum(K.abs(x[0] - x[1]), axis=1, keepdims=True))\n",
    "        return self.result\n",
    "\n",
    "    # return output shape\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return K.int_shape(self.result)\n",
    "\n",
    "\n",
    "# !/usr/bin/python\n",
    "\"\"\"\n",
    "Implementation of the Hungarian (Munkres) Algorithm using Python and NumPy\n",
    "References: http://www.ams.jhu.edu/~castello/362/Handouts/hungarian.pdf\n",
    "        http://weber.ucsd.edu/~vcrawfor/hungar.pdf\n",
    "        http://en.wikipedia.org/wiki/Hungarian_algorithm\n",
    "        http://www.public.iastate.edu/~ddoty/HungarianAlgorithm.html\n",
    "        http://www.clapper.org/software/python/munkres/\n",
    "\"\"\"\n",
    "\n",
    "# Module Information.\n",
    "__version__ = \"1.1.1\"\n",
    "__author__ = \"Thom Dedecko\"\n",
    "__url__ = \"http://github.com/tdedecko/hungarian-algorithm\"\n",
    "__copyright__ = \"(c) 2010 Thom Dedecko\"\n",
    "__license__ = \"MIT License\"\n",
    "\n",
    "\n",
    "class HungarianError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "# Import numpy. Error if fails\n",
    "try:\n",
    "    import numpy as np\n",
    "except ImportError:\n",
    "    raise HungarianError(\"NumPy is not installed.\")\n",
    "\n",
    "\n",
    "class Hungarian:\n",
    "    \"\"\"\n",
    "    Implementation of the Hungarian (Munkres) Algorithm using np.\n",
    "    Usage:\n",
    "        hungarian = Hungarian(cost_matrix)\n",
    "        hungarian.calculate()\n",
    "    or\n",
    "        hungarian = Hungarian()\n",
    "        hungarian.calculate(cost_matrix)\n",
    "    Handle Profit matrix:\n",
    "        hungarian = Hungarian(profit_matrix, is_profit_matrix=True)\n",
    "    or\n",
    "        cost_matrix = Hungarian.make_cost_matrix(profit_matrix)\n",
    "    The matrix will be automatically padded if it is not square.\n",
    "    For that numpy's resize function is used, which automatically adds 0's to any row/column that is added\n",
    "    Get results and total potential after calculation:\n",
    "        hungarian.get_results()\n",
    "        hungarian.get_total_potential()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_matrix=None, is_profit_matrix=False):\n",
    "        \"\"\"\n",
    "        input_matrix is a List of Lists.\n",
    "        input_matrix is assumed to be a cost matrix unless is_profit_matrix is True.\n",
    "        \"\"\"\n",
    "        if input_matrix is not None:\n",
    "            # Save input\n",
    "            my_matrix = np.array(input_matrix)\n",
    "            self._input_matrix = np.array(input_matrix)\n",
    "            self._maxColumn = my_matrix.shape[1]\n",
    "            self._maxRow = my_matrix.shape[0]\n",
    "\n",
    "            # Adds 0s if any columns/rows are added. Otherwise stays unaltered\n",
    "            matrix_size = max(self._maxColumn, self._maxRow)\n",
    "            pad_columns = matrix_size - self._maxRow\n",
    "            pad_rows = matrix_size - self._maxColumn\n",
    "            my_matrix = np.pad(my_matrix, ((0, pad_columns), (0, pad_rows)), 'constant', constant_values=(0))\n",
    "\n",
    "            # Convert matrix to profit matrix if necessary\n",
    "            if is_profit_matrix:\n",
    "                my_matrix = self.make_cost_matrix(my_matrix)\n",
    "\n",
    "            self._cost_matrix = my_matrix\n",
    "            self._size = len(my_matrix)\n",
    "            self._shape = my_matrix.shape\n",
    "\n",
    "            # Results from algorithm.\n",
    "            self._results = []\n",
    "            self._totalPotential = 0\n",
    "        else:\n",
    "            self._cost_matrix = None\n",
    "\n",
    "    def get_results(self):\n",
    "        \"\"\"Get results after calculation.\"\"\"\n",
    "        return self._results\n",
    "\n",
    "    def get_total_potential(self):\n",
    "        \"\"\"Returns expected value after calculation.\"\"\"\n",
    "        return self._totalPotential\n",
    "\n",
    "    def calculate(self, input_matrix=None, is_profit_matrix=False):\n",
    "        \"\"\"\n",
    "        Implementation of the Hungarian (Munkres) Algorithm.\n",
    "        input_matrix is a List of Lists.\n",
    "        input_matrix is assumed to be a cost matrix unless is_profit_matrix is True.\n",
    "        \"\"\"\n",
    "        # Handle invalid and new matrix inputs.\n",
    "        if input_matrix is None and self._cost_matrix is None:\n",
    "            raise HungarianError(\"Invalid input\")\n",
    "        elif input_matrix is not None:\n",
    "            self.__init__(input_matrix, is_profit_matrix)\n",
    "\n",
    "        result_matrix = self._cost_matrix.copy()\n",
    "\n",
    "        # Step 1: Subtract row mins from each row.\n",
    "        for index, row in enumerate(result_matrix):\n",
    "            result_matrix[index] -= row.min()\n",
    "\n",
    "        # Step 2: Subtract column mins from each column.\n",
    "        for index, column in enumerate(result_matrix.T):\n",
    "            result_matrix[:, index] -= column.min()\n",
    "\n",
    "        # Step 3: Use minimum number of lines to cover all zeros in the matrix.\n",
    "        # If the total covered rows+columns is not equal to the matrix size then adjust matrix and repeat.\n",
    "        total_covered = 0\n",
    "        while total_covered < self._size:\n",
    "            # Find minimum number of lines to cover all zeros in the matrix and find total covered rows and columns.\n",
    "            cover_zeros = CoverZeros(result_matrix)\n",
    "            covered_rows = cover_zeros.get_covered_rows()\n",
    "            covered_columns = cover_zeros.get_covered_columns()\n",
    "            total_covered = len(covered_rows) + len(covered_columns)\n",
    "\n",
    "            # if the total covered rows+columns is not equal to the matrix size then adjust it by min uncovered num (m).\n",
    "            if total_covered < self._size:\n",
    "                result_matrix = self._adjust_matrix_by_min_uncovered_num(result_matrix, covered_rows, covered_columns)\n",
    "\n",
    "        # Step 4: Starting with the top row, work your way downwards as you make assignments.\n",
    "        # Find single zeros in rows or columns.\n",
    "        # Add them to final result and remove them and their associated row/column from the matrix.\n",
    "        expected_results = min(self._maxColumn, self._maxRow)\n",
    "        zero_locations = (result_matrix == 0)\n",
    "        while len(self._results) != expected_results:\n",
    "\n",
    "            # If number of zeros in the matrix is zero before finding all the results then an error has occurred.\n",
    "            if not zero_locations.any():\n",
    "                raise HungarianError(\"Unable to find results. Algorithm has failed.\")\n",
    "\n",
    "            # Find results and mark rows and columns for deletion\n",
    "            matched_rows, matched_columns = self.__find_matches(zero_locations)\n",
    "\n",
    "            # Make arbitrary selection\n",
    "            total_matched = len(matched_rows) + len(matched_columns)\n",
    "            if total_matched == 0:\n",
    "                matched_rows, matched_columns = self.select_arbitrary_match(zero_locations)\n",
    "\n",
    "            # Delete rows and columns\n",
    "            for row in matched_rows:\n",
    "                zero_locations[row] = False\n",
    "            for column in matched_columns:\n",
    "                zero_locations[:, column] = False\n",
    "\n",
    "            # Save Results\n",
    "            self.__set_results(zip(matched_rows, matched_columns))\n",
    "\n",
    "        # Calculate total potential\n",
    "        value = 0\n",
    "        for row, column in self._results:\n",
    "            value += self._input_matrix[row, column]\n",
    "        self._totalPotential = value\n",
    "\n",
    "    @staticmethod\n",
    "    def make_cost_matrix(profit_matrix):\n",
    "        \"\"\"\n",
    "        Converts a profit matrix into a cost matrix.\n",
    "        Expects NumPy objects as input.\n",
    "        \"\"\"\n",
    "        # subtract profit matrix from a matrix made of the max value of the profit matrix\n",
    "        matrix_shape = profit_matrix.shape\n",
    "        offset_matrix = np.ones(matrix_shape, dtype=int) * profit_matrix.max()\n",
    "        cost_matrix = offset_matrix - profit_matrix\n",
    "        return cost_matrix\n",
    "\n",
    "    def _adjust_matrix_by_min_uncovered_num(self, result_matrix, covered_rows, covered_columns):\n",
    "        \"\"\"Subtract m from every uncovered number and add m to every element covered with two lines.\"\"\"\n",
    "        # Calculate minimum uncovered number (m)\n",
    "        elements = []\n",
    "        for row_index, row in enumerate(result_matrix):\n",
    "            if row_index not in covered_rows:\n",
    "                for index, element in enumerate(row):\n",
    "                    if index not in covered_columns:\n",
    "                        elements.append(element)\n",
    "        min_uncovered_num = min(elements)\n",
    "\n",
    "        # Add m to every covered element\n",
    "        adjusted_matrix = result_matrix\n",
    "        for row in covered_rows:\n",
    "            adjusted_matrix[row] += min_uncovered_num\n",
    "        for column in covered_columns:\n",
    "            adjusted_matrix[:, column] += min_uncovered_num\n",
    "\n",
    "        # Subtract m from every element\n",
    "        m_matrix = np.ones(self._shape, dtype=int) * min_uncovered_num\n",
    "        adjusted_matrix -= m_matrix\n",
    "\n",
    "        return adjusted_matrix\n",
    "\n",
    "    def __find_matches(self, zero_locations):\n",
    "        \"\"\"Returns rows and columns with matches in them.\"\"\"\n",
    "        marked_rows = np.array([], dtype=int)\n",
    "        marked_columns = np.array([], dtype=int)\n",
    "\n",
    "        # Mark rows and columns with matches\n",
    "        # Iterate over rows\n",
    "        for index, row in enumerate(zero_locations):\n",
    "            row_index = np.array([index])\n",
    "            if np.sum(row) == 1:\n",
    "                column_index, = np.where(row)\n",
    "                marked_rows, marked_columns = self.__mark_rows_and_columns(marked_rows, marked_columns, row_index,\n",
    "                                                                           column_index)\n",
    "\n",
    "        # Iterate over columns\n",
    "        for index, column in enumerate(zero_locations.T):\n",
    "            column_index = np.array([index])\n",
    "            if np.sum(column) == 1:\n",
    "                row_index, = np.where(column)\n",
    "                marked_rows, marked_columns = self.__mark_rows_and_columns(marked_rows, marked_columns, row_index,\n",
    "                                                                           column_index)\n",
    "\n",
    "        return marked_rows, marked_columns\n",
    "\n",
    "    @staticmethod\n",
    "    def __mark_rows_and_columns(marked_rows, marked_columns, row_index, column_index):\n",
    "        \"\"\"Check if column or row is marked. If not marked then mark it.\"\"\"\n",
    "        new_marked_rows = marked_rows\n",
    "        new_marked_columns = marked_columns\n",
    "        if not (marked_rows == row_index).any() and not (marked_columns == column_index).any():\n",
    "            new_marked_rows = np.insert(marked_rows, len(marked_rows), row_index)\n",
    "            new_marked_columns = np.insert(marked_columns, len(marked_columns), column_index)\n",
    "        return new_marked_rows, new_marked_columns\n",
    "\n",
    "    @staticmethod\n",
    "    def select_arbitrary_match(zero_locations):\n",
    "        \"\"\"Selects row column combination with minimum number of zeros in it.\"\"\"\n",
    "        # Count number of zeros in row and column combinations\n",
    "        rows, columns = np.where(zero_locations)\n",
    "        zero_count = []\n",
    "        for index, row in enumerate(rows):\n",
    "            total_zeros = np.sum(zero_locations[row]) + np.sum(zero_locations[:, columns[index]])\n",
    "            zero_count.append(total_zeros)\n",
    "\n",
    "        # Get the row column combination with the minimum number of zeros.\n",
    "        indices = zero_count.index(min(zero_count))\n",
    "        row = np.array([rows[indices]])\n",
    "        column = np.array([columns[indices]])\n",
    "\n",
    "        return row, column\n",
    "\n",
    "    def __set_results(self, result_lists):\n",
    "        \"\"\"Set results during calculation.\"\"\"\n",
    "        # Check if results values are out of bound from input matrix (because of matrix being padded).\n",
    "        # Add results to results list.\n",
    "        for result in result_lists:\n",
    "            row, column = result\n",
    "            if row < self._maxRow and column < self._maxColumn:\n",
    "                new_result = (int(row), int(column))\n",
    "                self._results.append(new_result)\n",
    "\n",
    "\n",
    "class CoverZeros:\n",
    "    \"\"\"\n",
    "    Use minimum number of lines to cover all zeros in the matrix.\n",
    "    Algorithm based on: http://weber.ucsd.edu/~vcrawfor/hungar.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, matrix):\n",
    "        \"\"\"\n",
    "        Input a matrix and save it as a boolean matrix to designate zero locations.\n",
    "        Run calculation procedure to generate results.\n",
    "        \"\"\"\n",
    "        # Find zeros in matrix\n",
    "        self._zero_locations = (matrix == 0)\n",
    "        self._shape = matrix.shape\n",
    "\n",
    "        # Choices starts without any choices made.\n",
    "        self._choices = np.zeros(self._shape, dtype=bool)\n",
    "\n",
    "        self._marked_rows = []\n",
    "        self._marked_columns = []\n",
    "\n",
    "        # marks rows and columns\n",
    "        self.__calculate()\n",
    "\n",
    "        # Draw lines through all unmarked rows and all marked columns.\n",
    "        self._covered_rows = list(set(range(self._shape[0])) - set(self._marked_rows))\n",
    "        self._covered_columns = self._marked_columns\n",
    "\n",
    "    def get_covered_rows(self):\n",
    "        \"\"\"Return list of covered rows.\"\"\"\n",
    "        return self._covered_rows\n",
    "\n",
    "    def get_covered_columns(self):\n",
    "        \"\"\"Return list of covered columns.\"\"\"\n",
    "        return self._covered_columns\n",
    "\n",
    "    def __calculate(self):\n",
    "        \"\"\"\n",
    "        Calculates minimum number of lines necessary to cover all zeros in a matrix.\n",
    "        Algorithm based on: http://weber.ucsd.edu/~vcrawfor/hungar.pdf\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            # Erase all marks.\n",
    "            self._marked_rows = []\n",
    "            self._marked_columns = []\n",
    "\n",
    "            # Mark all rows in which no choice has been made.\n",
    "            for index, row in enumerate(self._choices):\n",
    "                if not row.any():\n",
    "                    self._marked_rows.append(index)\n",
    "\n",
    "            # If no marked rows then finish.\n",
    "            if not self._marked_rows:\n",
    "                return True\n",
    "\n",
    "            # Mark all columns not already marked which have zeros in marked rows.\n",
    "            num_marked_columns = self.__mark_new_columns_with_zeros_in_marked_rows()\n",
    "\n",
    "            # If no new marked columns then finish.\n",
    "            if num_marked_columns == 0:\n",
    "                return True\n",
    "\n",
    "            # While there is some choice in every marked column.\n",
    "            while self.__choice_in_all_marked_columns():\n",
    "                # Some Choice in every marked column.\n",
    "\n",
    "                # Mark all rows not already marked which have choices in marked columns.\n",
    "                num_marked_rows = self.__mark_new_rows_with_choices_in_marked_columns()\n",
    "\n",
    "                # If no new marks then Finish.\n",
    "                if num_marked_rows == 0:\n",
    "                    return True\n",
    "\n",
    "                # Mark all columns not already marked which have zeros in marked rows.\n",
    "                num_marked_columns = self.__mark_new_columns_with_zeros_in_marked_rows()\n",
    "\n",
    "                # If no new marked columns then finish.\n",
    "                if num_marked_columns == 0:\n",
    "                    return True\n",
    "\n",
    "            # No choice in one or more marked columns.\n",
    "            # Find a marked column that does not have a choice.\n",
    "            choice_column_index = self.__find_marked_column_without_choice()\n",
    "\n",
    "            while choice_column_index is not None:\n",
    "                # Find a zero in the column indexed that does not have a row with a choice.\n",
    "                choice_row_index = self.__find_row_without_choice(choice_column_index)\n",
    "\n",
    "                # Check if an available row was found.\n",
    "                new_choice_column_index = None\n",
    "                if choice_row_index is None:\n",
    "                    # Find a good row to accomodate swap. Find its column pair.\n",
    "                    choice_row_index, new_choice_column_index = \\\n",
    "                        self.__find_best_choice_row_and_new_column(choice_column_index)\n",
    "\n",
    "                    # Delete old choice.\n",
    "                    self._choices[choice_row_index, new_choice_column_index] = False\n",
    "\n",
    "                # Set zero to choice.\n",
    "                self._choices[choice_row_index, choice_column_index] = True\n",
    "\n",
    "                # Loop again if choice is added to a row with a choice already in it.\n",
    "                choice_column_index = new_choice_column_index\n",
    "\n",
    "    def __mark_new_columns_with_zeros_in_marked_rows(self):\n",
    "        \"\"\"Mark all columns not already marked which have zeros in marked rows.\"\"\"\n",
    "        num_marked_columns = 0\n",
    "        for index, column in enumerate(self._zero_locations.T):\n",
    "            if index not in self._marked_columns:\n",
    "                if column.any():\n",
    "                    row_indices, = np.where(column)\n",
    "                    zeros_in_marked_rows = (set(self._marked_rows) & set(row_indices)) != set([])\n",
    "                    if zeros_in_marked_rows:\n",
    "                        self._marked_columns.append(index)\n",
    "                        num_marked_columns += 1\n",
    "        return num_marked_columns\n",
    "\n",
    "    def __mark_new_rows_with_choices_in_marked_columns(self):\n",
    "        \"\"\"Mark all rows not already marked which have choices in marked columns.\"\"\"\n",
    "        num_marked_rows = 0\n",
    "        for index, row in enumerate(self._choices):\n",
    "            if index not in self._marked_rows:\n",
    "                if row.any():\n",
    "                    column_index, = np.where(row)\n",
    "                    if column_index in self._marked_columns:\n",
    "                        self._marked_rows.append(index)\n",
    "                        num_marked_rows += 1\n",
    "        return num_marked_rows\n",
    "\n",
    "    def __choice_in_all_marked_columns(self):\n",
    "        \"\"\"Return Boolean True if there is a choice in all marked columns. Returns boolean False otherwise.\"\"\"\n",
    "        for column_index in self._marked_columns:\n",
    "            if not self._choices[:, column_index].any():\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def __find_marked_column_without_choice(self):\n",
    "        \"\"\"Find a marked column that does not have a choice.\"\"\"\n",
    "        for column_index in self._marked_columns:\n",
    "            if not self._choices[:, column_index].any():\n",
    "                return column_index\n",
    "\n",
    "        raise HungarianError(\n",
    "            \"Could not find a column without a choice. Failed to cover matrix zeros. Algorithm has failed.\")\n",
    "\n",
    "    def __find_row_without_choice(self, choice_column_index):\n",
    "        \"\"\"Find a row without a choice in it for the column indexed. If a row does not exist then return None.\"\"\"\n",
    "        row_indices, = np.where(self._zero_locations[:, choice_column_index])\n",
    "        for row_index in row_indices:\n",
    "            if not self._choices[row_index].any():\n",
    "                return row_index\n",
    "\n",
    "        # All rows have choices. Return None.\n",
    "        return None\n",
    "\n",
    "    def __find_best_choice_row_and_new_column(self, choice_column_index):\n",
    "        \"\"\"\n",
    "        Find a row index to use for the choice so that the column that needs to be changed is optimal.\n",
    "        Return a random row and column if unable to find an optimal selection.\n",
    "        \"\"\"\n",
    "        row_indices, = np.where(self._zero_locations[:, choice_column_index])\n",
    "        for row_index in row_indices:\n",
    "            column_indices, = np.where(self._choices[row_index])\n",
    "            column_index = column_indices[0]\n",
    "            if self.__find_row_without_choice(column_index) is not None:\n",
    "                return row_index, column_index\n",
    "\n",
    "        # Cannot find optimal row and column. Return a random row and column.\n",
    "        from random import shuffle\n",
    "\n",
    "        shuffle(row_indices)\n",
    "        column_index, = np.where(self._choices[row_indices[0]])\n",
    "        return row_indices[0], column_index[0]\n",
    "\n",
    "\n",
    "def tokenize_sentences_list(sentences_list, vocab_set=None):\n",
    "    \"\"\"Tokenize list of sentences\"\"\"\n",
    "\n",
    "    tokenized_list = list(map(tokenize_sentence, list(sentences_list)))\n",
    "\n",
    "    if vocab_set is not None:\n",
    "        for tokenized_sentence in tokenized_list:\n",
    "            for word in tokenized_sentence:\n",
    "                vocab_set.add(word)\n",
    "    return tokenized_list\n",
    "\n",
    "\n",
    "def tokenize_sentence(sentence):\n",
    "    \"\"\"Tokenize the sentence\"\"\"\n",
    "    tokens = []\n",
    "    last = 0\n",
    "\n",
    "    sentence = sentence.strip().lower()\n",
    "    for index, char in enumerate(sentence):\n",
    "        if char not in string.ascii_letters + \"0123456789\":\n",
    "            if sentence[last:index]:\n",
    "                tokens.append(sentence[last:index])\n",
    "            if sentence[index].strip():\n",
    "                tokens.append(sentence[index])\n",
    "            last = index + 1\n",
    "    if sentence[last:].strip():\n",
    "        tokens.append(sentence[last:])\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "PADDING_TOKEN = \"þ\"\n",
    "\n",
    "\n",
    "def pad_sequences_wrapped(sequence_list):\n",
    "    is_str = type(sequence_list[0][0]) == str\n",
    "    return pad_sequences(sequence_list, padding=\"post\", truncating=\"post\", dtype=object if is_str else np.int32, value=PADDING_TOKEN if is_str else 0.)\n",
    "\n",
    "\n",
    "def vectorize_demo_data(q1, q2):\n",
    "    q1 = tokenize_sentences_list(q1)\n",
    "    q2 = tokenize_sentences_list(q2)\n",
    "\n",
    "    q1_len = list(map(lambda item: len(item), q1))\n",
    "    q2_len = list(map(lambda item: len(item), q2))\n",
    "\n",
    "    q1 = pad_sequences_wrapped(q1)\n",
    "    q2 = pad_sequences_wrapped(q2)\n",
    "\n",
    "    return np.array(q1), np.array(q1_len).reshape((-1, 1)), np.array(q2), np.array(q2_len).reshape((-1, 1))\n",
    "\n",
    "\n",
    "model_root = None\n",
    "######################################\n",
    "\n",
    "state_size = 300\n",
    "staked_layers = 3\n",
    "\n",
    "\n",
    "######################################\n",
    "def possible_pairs(vectorized_field_names, vectorized_field_values):\n",
    "    field_names_side = []\n",
    "    field_values_side = []\n",
    "    for vectorized_field_name in vectorized_field_names:\n",
    "        for vectorized_field_value in vectorized_field_values:\n",
    "            field_names_side.append(vectorized_field_name)\n",
    "            field_values_side.append(vectorized_field_value)\n",
    "    return field_names_side, field_values_side\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    global model_root\n",
    "    model_root = model_dir\n",
    "    with K.get_session().graph.as_default():\n",
    "        siamese = model_from_json(open(os.path.join(model_root, 'w8s.arch'), \"r\").read(), \n",
    "                                  custom_objects={'_custom_stacked_bidirectional_GRU': \n",
    "                                                  custom_stacked_bidirectional_GRU_layer(state_size, staked_layers), \n",
    "                                                  \"CustomElmoEmbeddingLayer\": CustomElmoEmbeddingLayer, \n",
    "                                                  \"ManDistanceLayer\": ManDistanceLayer})\n",
    "        print(siamese.summary())\n",
    "        siamese.load_weights(os.path.join(model_root, \"w8s.h5\"))\n",
    "\n",
    "    return siamese\n",
    "\n",
    "\n",
    "def transform_fn(loaded_model, data, input_content_type, output_content_type):\n",
    "    data = json.loads(data)\n",
    "    field_names = data[\"field_names\"]\n",
    "    field_values = data[\"field_values\"]\n",
    "\n",
    "    field_names_side, field_values_side = possible_pairs(field_names, field_values)\n",
    "    field_vec, field_len, value_vec, value_len = vectorize_demo_data(field_names_side, field_values_side)\n",
    "\n",
    "    with K.get_session().graph.as_default():\n",
    "        prediction = loaded_model.predict([field_vec, field_len, value_vec, value_len])\n",
    "\n",
    "    ####################################################\n",
    "    # greedy approach\n",
    "    response = []  # {\"field\":\"string\",\"predictions\":[{\"value\":\"string\",\"score\":float},..]}\n",
    "    cost_matrix = []\n",
    "    for field_index in range(len(field_names)):\n",
    "        predictions = prediction[field_index * len(field_values):(field_index + 1) * len(field_values)]\n",
    "        cost_matrix.append((1 - predictions).squeeze(axis=-1).tolist())\n",
    "        predicted_indexes = np.argsort(predictions, axis=0)\n",
    "\n",
    "        field_predictions = []\n",
    "        for predicted_index in predicted_indexes[::-1, 0]:\n",
    "            field_predictions.append({\"value\": field_values[predicted_index], \"score\": float(predictions[predicted_index][0])})\n",
    "\n",
    "        response.append({\"field\": field_names[field_index], \"predictions\": field_predictions})\n",
    "    ####################################################\n",
    "    # hangarian approach\n",
    "    hungarian = Hungarian(cost_matrix)\n",
    "    hungarian.calculate()\n",
    "    # [\"field\":\"string\",\"value\":\"string\"]\n",
    "    new_response = []\n",
    "    for h_result in hungarian.get_results():\n",
    "        h_field, h_value = h_result\n",
    "        new_response.append({\"field\": field_names[h_field], \"value\": field_values[h_value], \"score\": 1 - cost_matrix[h_field][h_value]})\n",
    "    ####################################################\n",
    "    return json.dumps(new_response), output_content_type\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "from tensorflow.python.keras.engine.saving import model_from_json\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.python.layers.base import Layer\n",
    "from tensorflow.python.ops.rnn_cell_impl import MultiRNNCell\n",
    "def model_fn(model_dir):\n",
    "    global model_root\n",
    "    model_root = model_dir\n",
    "    with K.get_session().graph.as_default():\n",
    "        siamese = model_from_json(open(os.path.join(model_root, 'w8s.arch'), \"r\").read(), \n",
    "                                  custom_objects={'_custom_stacked_bidirectional_GRU': custom_stacked_bidirectional_GRU_layer(state_size, staked_layers), \n",
    "                                                  \"CustomElmoEmbeddingLayer\": CustomElmoEmbeddingLayer, \n",
    "                                                  \"ManDistanceLayer\": ManDistanceLayer})\n",
    "        print(siamese.summary())\n",
    "        siamese.load_weights(os.path.join(model_root, \"w8s.h5\"))\n",
    "\n",
    "    return siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root = '.'\n",
    "with K.get_session().graph.as_default():\n",
    "    siamese = model_from_json(open(os.path.join(model_root, 'w8s.arch'), \"r\").read(), \n",
    "                              custom_objects={'_custom_stacked_bidirectional_GRU': \n",
    "                                              custom_stacked_bidirectional_GRU_layer(state_size, staked_layers), \n",
    "                                              \"CustomElmoEmbeddingLayer\": CustomElmoEmbeddingLayer, \n",
    "                                              \"ManDistanceLayer\": ManDistanceLayer})\n",
    "    print(siamese.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese = model_fn('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
