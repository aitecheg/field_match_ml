{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/elsallab/Work/cod/siamese_text/repo\")\n",
    "#os.chdir(\"/home/elsallab/Work/cod/siamese_text/quora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-02 07:07:20,111 : INFO : read 10000 sentences\n",
      "2019-01-02 07:07:20,725 : INFO : read 20000 sentences\n",
      "2019-01-02 07:07:21,287 : INFO : read 30000 sentences\n",
      "2019-01-02 07:07:22,431 : INFO : read 40000 sentences\n",
      "2019-01-02 07:07:23,196 : INFO : read 50000 sentences\n",
      "2019-01-02 07:07:23,762 : INFO : read 60000 sentences\n",
      "2019-01-02 07:07:24,404 : INFO : read 70000 sentences\n",
      "2019-01-02 07:07:24,969 : INFO : read 80000 sentences\n",
      "2019-01-02 07:07:25,764 : INFO : read 90000 sentences\n",
      "example tokenization i authorize unum to leave message about my claim on my voicemail / answering machine. ['i', 'authorize', 'unum', 'to', 'leave', 'message', 'about', 'my', 'claim', 'on', 'my', 'voicemail', '/', 'answering', 'machine', '.']\n",
      "2019-01-02 07:07:26,713 : INFO : read 100000 sentences\n",
      "2019-01-02 07:07:27,435 : INFO : read 110000 sentences\n",
      "2019-01-02 07:07:28,052 : INFO : read 120000 sentences\n",
      "2019-01-02 07:07:28,674 : INFO : read 130000 sentences\n",
      "2019-01-02 07:07:29,301 : INFO : read 140000 sentences\n",
      "2019-01-02 07:07:29,922 : INFO : read 150000 sentences\n",
      "2019-01-02 07:07:30,826 : INFO : read 160000 sentences\n",
      "2019-01-02 07:07:31,641 : INFO : read 170000 sentences\n",
      "2019-01-02 07:07:32,692 : INFO : read 180000 sentences\n",
      "2019-01-02 07:07:33,285 : INFO : read 190000 sentences\n",
      "example tokenization date of follow up visit following confinement or outpatient surgery ['date', 'of', 'follow', 'up', 'visit', 'following', 'confinement', 'or', 'outpatient', 'surgery']\n",
      "2019-01-02 07:07:33,855 : INFO : read 200000 sentences\n",
      "2019-01-02 07:07:34,416 : INFO : read 210000 sentences\n",
      "2019-01-02 07:07:35,098 : INFO : read 220000 sentences\n",
      "2019-01-02 07:07:35,654 : INFO : read 230000 sentences\n",
      "2019-01-02 07:07:36,496 : INFO : read 240000 sentences\n",
      "2019-01-02 07:07:37,233 : INFO : read 250000 sentences\n",
      "2019-01-02 07:07:38,148 : INFO : read 260000 sentences\n",
      "2019-01-02 07:07:38,708 : INFO : read 270000 sentences\n",
      "2019-01-02 07:07:39,278 : INFO : read 280000 sentences\n",
      "2019-01-02 07:07:39,987 : INFO : read 290000 sentences\n",
      "example tokenization mi ['mi']\n",
      "2019-01-02 07:07:40,542 : INFO : read 300000 sentences\n",
      "2019-01-02 07:07:41,098 : INFO : read 310000 sentences\n",
      "2019-01-02 07:07:41,656 : INFO : read 320000 sentences\n",
      "2019-01-02 07:07:42,467 : INFO : read 330000 sentences\n",
      "2019-01-02 07:07:43,360 : INFO : read 340000 sentences\n",
      "2019-01-02 07:07:44,475 : INFO : read 350000 sentences\n",
      "2019-01-02 07:07:45,125 : INFO : read 360000 sentences\n",
      "2019-01-02 07:07:45,705 : INFO : read 370000 sentences\n",
      "2019-01-02 07:07:46,452 : INFO : read 380000 sentences\n",
      "2019-01-02 07:07:47,489 : INFO : read 390000 sentences\n",
      "2019-01-02 07:07:48,866 : INFO : read 10000 sentences\n",
      "2019-01-02 07:07:49,428 : INFO : read 20000 sentences\n",
      "2019-01-02 07:07:49,491 : INFO : Done reading data file\n",
      "2019-01-02 07:07:49,491 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-01-02 07:07:49,491 : INFO : collecting all words and their counts\n",
      "2019-01-02 07:07:49,491 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-01-02 07:07:49,497 : INFO : PROGRESS: at sentence #10000, processed 37155 words, keeping 5505 word types\n",
      "2019-01-02 07:07:49,503 : INFO : PROGRESS: at sentence #20000, processed 74647 words, keeping 8954 word types\n",
      "2019-01-02 07:07:49,509 : INFO : PROGRESS: at sentence #30000, processed 112685 words, keeping 11914 word types\n",
      "2019-01-02 07:07:49,515 : INFO : PROGRESS: at sentence #40000, processed 150913 words, keeping 14504 word types\n",
      "2019-01-02 07:07:49,521 : INFO : PROGRESS: at sentence #50000, processed 188787 words, keeping 16919 word types\n",
      "2019-01-02 07:07:49,528 : INFO : PROGRESS: at sentence #60000, processed 226640 words, keeping 19163 word types\n",
      "2019-01-02 07:07:49,534 : INFO : PROGRESS: at sentence #70000, processed 263951 words, keeping 21327 word types\n",
      "2019-01-02 07:07:49,541 : INFO : PROGRESS: at sentence #80000, processed 301245 words, keeping 23302 word types\n",
      "2019-01-02 07:07:49,548 : INFO : PROGRESS: at sentence #90000, processed 339188 words, keeping 25177 word types\n",
      "2019-01-02 07:07:49,554 : INFO : PROGRESS: at sentence #100000, processed 376483 words, keeping 27026 word types\n",
      "2019-01-02 07:07:49,561 : INFO : PROGRESS: at sentence #110000, processed 413766 words, keeping 28751 word types\n",
      "2019-01-02 07:07:49,567 : INFO : PROGRESS: at sentence #120000, processed 450878 words, keeping 30349 word types\n",
      "2019-01-02 07:07:49,574 : INFO : PROGRESS: at sentence #130000, processed 488727 words, keeping 31965 word types\n",
      "2019-01-02 07:07:49,581 : INFO : PROGRESS: at sentence #140000, processed 525860 words, keeping 33535 word types\n",
      "2019-01-02 07:07:49,588 : INFO : PROGRESS: at sentence #150000, processed 563982 words, keeping 35098 word types\n",
      "2019-01-02 07:07:49,596 : INFO : PROGRESS: at sentence #160000, processed 601788 words, keeping 36601 word types\n",
      "2019-01-02 07:07:49,603 : INFO : PROGRESS: at sentence #170000, processed 639892 words, keeping 38060 word types\n",
      "2019-01-02 07:07:49,611 : INFO : PROGRESS: at sentence #180000, processed 677081 words, keeping 39473 word types\n",
      "2019-01-02 07:07:49,619 : INFO : PROGRESS: at sentence #190000, processed 714418 words, keeping 40828 word types\n",
      "2019-01-02 07:07:49,626 : INFO : PROGRESS: at sentence #200000, processed 751269 words, keeping 42163 word types\n",
      "2019-01-02 07:07:49,634 : INFO : PROGRESS: at sentence #210000, processed 789013 words, keeping 43490 word types\n",
      "2019-01-02 07:07:49,642 : INFO : PROGRESS: at sentence #220000, processed 826573 words, keeping 44723 word types\n",
      "2019-01-02 07:07:49,650 : INFO : PROGRESS: at sentence #230000, processed 863918 words, keeping 45998 word types\n",
      "2019-01-02 07:07:49,657 : INFO : PROGRESS: at sentence #240000, processed 901505 words, keeping 47237 word types\n",
      "2019-01-02 07:07:49,665 : INFO : PROGRESS: at sentence #250000, processed 938770 words, keeping 48498 word types\n",
      "2019-01-02 07:07:49,672 : INFO : PROGRESS: at sentence #260000, processed 976092 words, keeping 49743 word types\n",
      "2019-01-02 07:07:49,680 : INFO : PROGRESS: at sentence #270000, processed 1013382 words, keeping 50908 word types\n",
      "2019-01-02 07:07:49,688 : INFO : PROGRESS: at sentence #280000, processed 1051078 words, keeping 52065 word types\n",
      "2019-01-02 07:07:49,695 : INFO : PROGRESS: at sentence #290000, processed 1088957 words, keeping 53232 word types\n",
      "2019-01-02 07:07:49,703 : INFO : PROGRESS: at sentence #300000, processed 1125939 words, keeping 54400 word types\n",
      "2019-01-02 07:07:49,711 : INFO : PROGRESS: at sentence #310000, processed 1164008 words, keeping 55527 word types\n",
      "2019-01-02 07:07:49,718 : INFO : PROGRESS: at sentence #320000, processed 1201739 words, keeping 56593 word types\n",
      "2019-01-02 07:07:49,726 : INFO : PROGRESS: at sentence #330000, processed 1239136 words, keeping 57752 word types\n",
      "2019-01-02 07:07:49,733 : INFO : PROGRESS: at sentence #340000, processed 1276618 words, keeping 58824 word types\n",
      "2019-01-02 07:07:49,741 : INFO : PROGRESS: at sentence #350000, processed 1313736 words, keeping 59883 word types\n",
      "2019-01-02 07:07:49,748 : INFO : PROGRESS: at sentence #360000, processed 1351115 words, keeping 60974 word types\n",
      "2019-01-02 07:07:49,756 : INFO : PROGRESS: at sentence #370000, processed 1388963 words, keeping 62052 word types\n",
      "2019-01-02 07:07:49,763 : INFO : PROGRESS: at sentence #380000, processed 1426528 words, keeping 63100 word types\n",
      "2019-01-02 07:07:49,770 : INFO : PROGRESS: at sentence #390000, processed 1463322 words, keeping 64129 word types\n",
      "2019-01-02 07:07:49,778 : INFO : PROGRESS: at sentence #400000, processed 1500335 words, keeping 65153 word types\n",
      "2019-01-02 07:07:49,785 : INFO : PROGRESS: at sentence #410000, processed 1538056 words, keeping 66170 word types\n",
      "2019-01-02 07:07:49,792 : INFO : PROGRESS: at sentence #420000, processed 1575260 words, keeping 67190 word types\n",
      "2019-01-02 07:07:49,799 : INFO : PROGRESS: at sentence #430000, processed 1613175 words, keeping 68214 word types\n",
      "2019-01-02 07:07:49,807 : INFO : PROGRESS: at sentence #440000, processed 1650877 words, keeping 69264 word types\n",
      "2019-01-02 07:07:49,814 : INFO : PROGRESS: at sentence #450000, processed 1688490 words, keeping 70251 word types\n",
      "2019-01-02 07:07:49,821 : INFO : PROGRESS: at sentence #460000, processed 1726273 words, keeping 71243 word types\n",
      "2019-01-02 07:07:49,828 : INFO : PROGRESS: at sentence #470000, processed 1763648 words, keeping 72189 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-02 07:07:49,835 : INFO : PROGRESS: at sentence #480000, processed 1800552 words, keeping 73180 word types\n",
      "2019-01-02 07:07:49,842 : INFO : PROGRESS: at sentence #490000, processed 1838216 words, keeping 74152 word types\n",
      "2019-01-02 07:07:49,849 : INFO : PROGRESS: at sentence #500000, processed 1875815 words, keeping 75124 word types\n",
      "2019-01-02 07:07:49,857 : INFO : PROGRESS: at sentence #510000, processed 1913498 words, keeping 76085 word types\n",
      "2019-01-02 07:07:49,864 : INFO : PROGRESS: at sentence #520000, processed 1950365 words, keeping 77037 word types\n",
      "2019-01-02 07:07:49,871 : INFO : PROGRESS: at sentence #530000, processed 1988102 words, keeping 78008 word types\n",
      "2019-01-02 07:07:49,878 : INFO : PROGRESS: at sentence #540000, processed 2025555 words, keeping 78938 word types\n",
      "2019-01-02 07:07:49,885 : INFO : PROGRESS: at sentence #550000, processed 2063713 words, keeping 79907 word types\n",
      "2019-01-02 07:07:49,892 : INFO : PROGRESS: at sentence #560000, processed 2101121 words, keeping 80846 word types\n",
      "2019-01-02 07:07:49,900 : INFO : PROGRESS: at sentence #570000, processed 2138860 words, keeping 81841 word types\n",
      "2019-01-02 07:07:49,907 : INFO : PROGRESS: at sentence #580000, processed 2176478 words, keeping 82780 word types\n",
      "2019-01-02 07:07:49,914 : INFO : PROGRESS: at sentence #590000, processed 2214065 words, keeping 83706 word types\n",
      "2019-01-02 07:07:49,921 : INFO : PROGRESS: at sentence #600000, processed 2251768 words, keeping 84672 word types\n",
      "2019-01-02 07:07:49,928 : INFO : PROGRESS: at sentence #610000, processed 2289661 words, keeping 85570 word types\n",
      "2019-01-02 07:07:49,935 : INFO : PROGRESS: at sentence #620000, processed 2327339 words, keeping 86495 word types\n",
      "2019-01-02 07:07:49,945 : INFO : PROGRESS: at sentence #630000, processed 2364505 words, keeping 87447 word types\n",
      "2019-01-02 07:07:49,952 : INFO : PROGRESS: at sentence #640000, processed 2401682 words, keeping 88328 word types\n",
      "2019-01-02 07:07:49,960 : INFO : PROGRESS: at sentence #650000, processed 2439740 words, keeping 89252 word types\n",
      "2019-01-02 07:07:49,967 : INFO : PROGRESS: at sentence #660000, processed 2477479 words, keeping 90171 word types\n",
      "2019-01-02 07:07:49,974 : INFO : PROGRESS: at sentence #670000, processed 2515281 words, keeping 91040 word types\n",
      "2019-01-02 07:07:49,982 : INFO : PROGRESS: at sentence #680000, processed 2552339 words, keeping 91914 word types\n",
      "2019-01-02 07:07:49,990 : INFO : PROGRESS: at sentence #690000, processed 2590122 words, keeping 92854 word types\n",
      "2019-01-02 07:07:49,998 : INFO : PROGRESS: at sentence #700000, processed 2627035 words, keeping 93777 word types\n",
      "2019-01-02 07:07:50,006 : INFO : PROGRESS: at sentence #710000, processed 2664391 words, keeping 94700 word types\n",
      "2019-01-02 07:07:50,014 : INFO : PROGRESS: at sentence #720000, processed 2702655 words, keeping 95564 word types\n",
      "2019-01-02 07:07:50,022 : INFO : PROGRESS: at sentence #730000, processed 2740060 words, keeping 96494 word types\n",
      "2019-01-02 07:07:50,031 : INFO : PROGRESS: at sentence #740000, processed 2777132 words, keeping 97358 word types\n",
      "2019-01-02 07:07:50,039 : INFO : PROGRESS: at sentence #750000, processed 2814893 words, keeping 98240 word types\n",
      "2019-01-02 07:07:50,047 : INFO : PROGRESS: at sentence #760000, processed 2852227 words, keeping 99122 word types\n",
      "2019-01-02 07:07:50,055 : INFO : PROGRESS: at sentence #770000, processed 2889434 words, keeping 99981 word types\n",
      "2019-01-02 07:07:50,062 : INFO : PROGRESS: at sentence #780000, processed 2926566 words, keeping 100841 word types\n",
      "2019-01-02 07:07:50,070 : INFO : PROGRESS: at sentence #790000, processed 2964013 words, keeping 101720 word types\n",
      "2019-01-02 07:07:50,078 : INFO : PROGRESS: at sentence #800000, processed 3001252 words, keeping 102602 word types\n",
      "2019-01-02 07:07:50,086 : INFO : PROGRESS: at sentence #810000, processed 3038857 words, keeping 103487 word types\n",
      "2019-01-02 07:07:50,094 : INFO : PROGRESS: at sentence #820000, processed 3076491 words, keeping 104377 word types\n",
      "2019-01-02 07:07:50,102 : INFO : PROGRESS: at sentence #830000, processed 3113668 words, keeping 105234 word types\n",
      "2019-01-02 07:07:50,109 : INFO : collected 106100 word types from a corpus of 3151036 raw words and 840000 sentences\n",
      "2019-01-02 07:07:50,109 : INFO : Loading a fresh vocabulary\n",
      "2019-01-02 07:07:50,165 : INFO : effective_min_count=3 retains 25806 unique words (24% of original 106100, drops 80294)\n",
      "2019-01-02 07:07:50,165 : INFO : effective_min_count=3 leaves 3062833 word corpus (97% of original 3151036, drops 88203)\n",
      "2019-01-02 07:07:50,217 : INFO : deleting the raw counts dictionary of 106100 items\n",
      "2019-01-02 07:07:50,219 : INFO : sample=0.001 downsamples 66 most-common words\n",
      "2019-01-02 07:07:50,219 : INFO : downsampling leaves estimated 2017592 word corpus (65.9% of prior 3062833)\n",
      "2019-01-02 07:07:50,428 : INFO : estimated required memory for 25806 words, 158406 buckets and 250 dimensions: 227405720 bytes\n",
      "2019-01-02 07:07:50,434 : INFO : resetting layer weights\n",
      "2019-01-02 07:07:51,739 : INFO : Total number of ngrams is 158406\n",
      "2019-01-02 07:07:53,190 : INFO : training model with 3 workers on 25806 vocabulary and 250 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-01-02 07:07:54,214 : INFO : EPOCH 1 - PROGRESS: at 20.88% examples, 417368 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:07:55,220 : INFO : EPOCH 1 - PROGRESS: at 42.17% examples, 421518 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:07:56,232 : INFO : EPOCH 1 - PROGRESS: at 56.15% examples, 373745 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:07:57,248 : INFO : EPOCH 1 - PROGRESS: at 68.82% examples, 343170 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:07:58,278 : INFO : EPOCH 1 - PROGRESS: at 88.16% examples, 350389 words/s, in_qsize 4, out_qsize 1\n",
      "2019-01-02 07:07:58,769 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-02 07:07:58,774 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-02 07:07:58,794 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-02 07:07:58,794 : INFO : EPOCH - 1 : training on 3151036 raw words (2016537 effective words) took 5.6s, 360582 effective words/s\n",
      "2019-01-02 07:07:59,800 : INFO : EPOCH 2 - PROGRESS: at 21.83% examples, 441986 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:00,802 : INFO : EPOCH 2 - PROGRESS: at 44.38% examples, 447662 words/s, in_qsize 6, out_qsize 0\n",
      "2019-01-02 07:08:01,807 : INFO : EPOCH 2 - PROGRESS: at 62.50% examples, 419634 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:02,833 : INFO : EPOCH 2 - PROGRESS: at 79.89% examples, 400079 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:03,838 : INFO : EPOCH 2 - PROGRESS: at 93.26% examples, 373593 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:04,239 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-02 07:08:04,241 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-02 07:08:04,252 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-02 07:08:04,253 : INFO : EPOCH - 2 : training on 3151036 raw words (2017587 effective words) took 5.5s, 370031 effective words/s\n",
      "2019-01-02 07:08:05,298 : INFO : EPOCH 3 - PROGRESS: at 23.11% examples, 465965 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:06,313 : INFO : EPOCH 3 - PROGRESS: at 45.98% examples, 460230 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:07,322 : INFO : EPOCH 3 - PROGRESS: at 61.55% examples, 410352 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:08,337 : INFO : EPOCH 3 - PROGRESS: at 75.15% examples, 375454 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:09,339 : INFO : EPOCH 3 - PROGRESS: at 96.44% examples, 385882 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:09,458 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-02 07:08:09,458 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-02 07:08:09,466 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-02 07:08:09,466 : INFO : EPOCH - 3 : training on 3151036 raw words (2017586 effective words) took 5.2s, 390162 effective words/s\n",
      "2019-01-02 07:08:10,482 : INFO : EPOCH 4 - PROGRESS: at 19.60% examples, 395485 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-02 07:08:11,494 : INFO : EPOCH 4 - PROGRESS: at 35.51% examples, 355517 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:12,502 : INFO : EPOCH 4 - PROGRESS: at 50.45% examples, 336531 words/s, in_qsize 4, out_qsize 1\n",
      "2019-01-02 07:08:13,505 : INFO : EPOCH 4 - PROGRESS: at 73.25% examples, 367330 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:14,522 : INFO : EPOCH 4 - PROGRESS: at 96.44% examples, 386041 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:14,646 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-02 07:08:14,650 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-02 07:08:14,655 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-02 07:08:14,655 : INFO : EPOCH - 4 : training on 3151036 raw words (2018356 effective words) took 5.2s, 389902 effective words/s\n",
      "2019-01-02 07:08:15,685 : INFO : EPOCH 5 - PROGRESS: at 22.79% examples, 451987 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:16,710 : INFO : EPOCH 5 - PROGRESS: at 39.94% examples, 394257 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:17,716 : INFO : EPOCH 5 - PROGRESS: at 57.43% examples, 379649 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:18,717 : INFO : EPOCH 5 - PROGRESS: at 70.41% examples, 350662 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:19,743 : INFO : EPOCH 5 - PROGRESS: at 90.38% examples, 359040 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:20,137 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-02 07:08:20,146 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-02 07:08:20,155 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-02 07:08:20,156 : INFO : EPOCH - 5 : training on 3151036 raw words (2016203 effective words) took 5.5s, 367211 effective words/s\n",
      "2019-01-02 07:08:21,166 : INFO : EPOCH 6 - PROGRESS: at 22.15% examples, 445848 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:22,172 : INFO : EPOCH 6 - PROGRESS: at 45.02% examples, 451777 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:23,185 : INFO : EPOCH 6 - PROGRESS: at 62.19% examples, 414834 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:24,191 : INFO : EPOCH 6 - PROGRESS: at 78.95% examples, 395480 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:25,212 : INFO : EPOCH 6 - PROGRESS: at 92.62% examples, 370006 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:25,514 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-02 07:08:25,519 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-02 07:08:25,536 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-02 07:08:25,536 : INFO : EPOCH - 6 : training on 3151036 raw words (2017349 effective words) took 5.4s, 375334 effective words/s\n",
      "2019-01-02 07:08:26,552 : INFO : EPOCH 7 - PROGRESS: at 21.83% examples, 439180 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:27,553 : INFO : EPOCH 7 - PROGRESS: at 44.38% examples, 446359 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:28,578 : INFO : EPOCH 7 - PROGRESS: at 63.46% examples, 422120 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:29,579 : INFO : EPOCH 7 - PROGRESS: at 80.21% examples, 401476 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:30,587 : INFO : EPOCH 7 - PROGRESS: at 92.94% examples, 371911 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:30,925 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-02 07:08:30,928 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-02 07:08:30,931 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-02 07:08:30,931 : INFO : EPOCH - 7 : training on 3151036 raw words (2016536 effective words) took 5.4s, 374499 effective words/s\n",
      "2019-01-02 07:08:31,937 : INFO : EPOCH 8 - PROGRESS: at 21.51% examples, 434928 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:32,938 : INFO : EPOCH 8 - PROGRESS: at 44.08% examples, 444670 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:33,944 : INFO : EPOCH 8 - PROGRESS: at 64.09% examples, 429789 words/s, in_qsize 4, out_qsize 1\n",
      "2019-01-02 07:08:34,971 : INFO : EPOCH 8 - PROGRESS: at 81.18% examples, 406088 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:35,977 : INFO : EPOCH 8 - PROGRESS: at 95.17% examples, 380958 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:36,146 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-02 07:08:36,149 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-02 07:08:36,165 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-02 07:08:36,165 : INFO : EPOCH - 8 : training on 3151036 raw words (2017223 effective words) took 5.2s, 385826 effective words/s\n",
      "2019-01-02 07:08:37,172 : INFO : EPOCH 9 - PROGRESS: at 21.51% examples, 435059 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:38,184 : INFO : EPOCH 9 - PROGRESS: at 44.38% examples, 445394 words/s, in_qsize 4, out_qsize 1\n",
      "2019-01-02 07:08:39,201 : INFO : EPOCH 9 - PROGRESS: at 61.87% examples, 412300 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:40,222 : INFO : EPOCH 9 - PROGRESS: at 79.26% examples, 395305 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:41,228 : INFO : EPOCH 9 - PROGRESS: at 94.52% examples, 377417 words/s, in_qsize 4, out_qsize 1\n",
      "2019-01-02 07:08:41,420 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-02 07:08:41,437 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-02 07:08:41,439 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-02 07:08:41,439 : INFO : EPOCH - 9 : training on 3151036 raw words (2017821 effective words) took 5.3s, 383048 effective words/s\n",
      "2019-01-02 07:08:42,455 : INFO : EPOCH 10 - PROGRESS: at 22.47% examples, 453394 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:43,467 : INFO : EPOCH 10 - PROGRESS: at 43.44% examples, 435235 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:44,482 : INFO : EPOCH 10 - PROGRESS: at 58.69% examples, 391097 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:45,482 : INFO : EPOCH 10 - PROGRESS: at 71.97% examples, 360862 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:46,486 : INFO : EPOCH 10 - PROGRESS: at 90.70% examples, 363877 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:46,861 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-02 07:08:46,862 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-02 07:08:46,866 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-02 07:08:46,866 : INFO : EPOCH - 10 : training on 3151036 raw words (2018661 effective words) took 5.4s, 372797 effective words/s\n",
      "2019-01-02 07:08:47,884 : INFO : EPOCH 11 - PROGRESS: at 22.47% examples, 449359 words/s, in_qsize 6, out_qsize 0\n",
      "2019-01-02 07:08:48,897 : INFO : EPOCH 11 - PROGRESS: at 44.38% examples, 442699 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:49,912 : INFO : EPOCH 11 - PROGRESS: at 61.23% examples, 406404 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:50,944 : INFO : EPOCH 11 - PROGRESS: at 75.48% examples, 374146 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:51,958 : INFO : EPOCH 11 - PROGRESS: at 98.66% examples, 391298 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:51,984 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-02 07:08:51,988 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-02 07:08:52,009 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-02 07:08:52,009 : INFO : EPOCH - 11 : training on 3151036 raw words (2017004 effective words) took 5.1s, 392681 effective words/s\n",
      "2019-01-02 07:08:53,034 : INFO : EPOCH 12 - PROGRESS: at 22.79% examples, 454994 words/s, in_qsize 4, out_qsize 1\n",
      "2019-01-02 07:08:54,038 : INFO : EPOCH 12 - PROGRESS: at 41.86% examples, 418853 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:55,042 : INFO : EPOCH 12 - PROGRESS: at 58.06% examples, 387635 words/s, in_qsize 4, out_qsize 1\n",
      "2019-01-02 07:08:56,054 : INFO : EPOCH 12 - PROGRESS: at 74.19% examples, 371397 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:57,063 : INFO : EPOCH 12 - PROGRESS: at 96.12% examples, 384623 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-02 07:08:57,195 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-02 07:08:57,196 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-02 07:08:57,214 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-02 07:08:57,214 : INFO : EPOCH - 12 : training on 3151036 raw words (2017263 effective words) took 5.2s, 388410 effective words/s\n",
      "2019-01-02 07:08:58,255 : INFO : EPOCH 13 - PROGRESS: at 20.24% examples, 398346 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:08:59,301 : INFO : EPOCH 13 - PROGRESS: at 37.08% examples, 360588 words/s, in_qsize 4, out_qsize 1\n",
      "2019-01-02 07:09:00,310 : INFO : EPOCH 13 - PROGRESS: at 49.82% examples, 325699 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:01,315 : INFO : EPOCH 13 - PROGRESS: at 71.35% examples, 352064 words/s, in_qsize 6, out_qsize 1\n",
      "2019-01-02 07:09:02,327 : INFO : EPOCH 13 - PROGRESS: at 93.26% examples, 368773 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:02,588 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-02 07:09:02,599 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-02 07:09:02,604 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-02 07:09:02,604 : INFO : EPOCH - 13 : training on 3151036 raw words (2016803 effective words) took 5.4s, 374931 effective words/s\n",
      "2019-01-02 07:09:03,620 : INFO : EPOCH 14 - PROGRESS: at 21.83% examples, 437331 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:04,629 : INFO : EPOCH 14 - PROGRESS: at 40.26% examples, 402442 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:05,654 : INFO : EPOCH 14 - PROGRESS: at 58.06% examples, 384668 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:06,675 : INFO : EPOCH 14 - PROGRESS: at 71.97% examples, 357458 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:07,681 : INFO : EPOCH 14 - PROGRESS: at 93.26% examples, 371026 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:07,976 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-02 07:09:07,982 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-02 07:09:08,002 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-02 07:09:08,002 : INFO : EPOCH - 14 : training on 3151036 raw words (2016772 effective words) took 5.4s, 374057 effective words/s\n",
      "2019-01-02 07:09:09,012 : INFO : EPOCH 15 - PROGRESS: at 22.15% examples, 446259 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:10,020 : INFO : EPOCH 15 - PROGRESS: at 44.07% examples, 441861 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:11,021 : INFO : EPOCH 15 - PROGRESS: at 60.91% examples, 407703 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:12,040 : INFO : EPOCH 15 - PROGRESS: at 78.01% examples, 390381 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:13,064 : INFO : EPOCH 15 - PROGRESS: at 90.39% examples, 360661 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:13,437 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-02 07:09:13,444 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-02 07:09:13,457 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-02 07:09:13,457 : INFO : EPOCH - 15 : training on 3151036 raw words (2016831 effective words) took 5.4s, 370114 effective words/s\n",
      "2019-01-02 07:09:14,484 : INFO : EPOCH 16 - PROGRESS: at 22.15% examples, 441200 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:15,488 : INFO : EPOCH 16 - PROGRESS: at 45.02% examples, 450029 words/s, in_qsize 6, out_qsize 0\n",
      "2019-01-02 07:09:16,512 : INFO : EPOCH 16 - PROGRESS: at 61.23% examples, 405873 words/s, in_qsize 4, out_qsize 1\n",
      "2019-01-02 07:09:17,515 : INFO : EPOCH 16 - PROGRESS: at 74.19% examples, 370167 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:18,520 : INFO : EPOCH 16 - PROGRESS: at 90.06% examples, 359879 words/s, in_qsize 6, out_qsize 0\n",
      "2019-01-02 07:09:18,934 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-02 07:09:18,952 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-02 07:09:18,954 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-02 07:09:18,954 : INFO : EPOCH - 16 : training on 3151036 raw words (2017384 effective words) took 5.5s, 367768 effective words/s\n",
      "2019-01-02 07:09:19,968 : INFO : EPOCH 17 - PROGRESS: at 21.83% examples, 438139 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:20,978 : INFO : EPOCH 17 - PROGRESS: at 43.44% examples, 434462 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:21,987 : INFO : EPOCH 17 - PROGRESS: at 59.01% examples, 393260 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:23,005 : INFO : EPOCH 17 - PROGRESS: at 71.97% examples, 359348 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:24,013 : INFO : EPOCH 17 - PROGRESS: at 91.02% examples, 363564 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:24,391 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-02 07:09:24,398 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-02 07:09:24,404 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-02 07:09:24,404 : INFO : EPOCH - 17 : training on 3151036 raw words (2017862 effective words) took 5.4s, 370633 effective words/s\n",
      "2019-01-02 07:09:25,412 : INFO : EPOCH 18 - PROGRESS: at 21.51% examples, 434511 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:26,433 : INFO : EPOCH 18 - PROGRESS: at 37.40% examples, 373176 words/s, in_qsize 4, out_qsize 1\n",
      "2019-01-02 07:09:27,449 : INFO : EPOCH 18 - PROGRESS: at 50.45% examples, 335019 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:28,464 : INFO : EPOCH 18 - PROGRESS: at 70.41% examples, 350684 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:29,480 : INFO : EPOCH 18 - PROGRESS: at 92.94% examples, 369956 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:29,773 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-02 07:09:29,784 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-02 07:09:29,793 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-02 07:09:29,793 : INFO : EPOCH - 18 : training on 3151036 raw words (2017817 effective words) took 5.4s, 374837 effective words/s\n",
      "2019-01-02 07:09:30,825 : INFO : EPOCH 19 - PROGRESS: at 21.20% examples, 422785 words/s, in_qsize 4, out_qsize 0\n",
      "2019-01-02 07:09:31,840 : INFO : EPOCH 19 - PROGRESS: at 37.39% examples, 371938 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:32,841 : INFO : EPOCH 19 - PROGRESS: at 51.71% examples, 344128 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:33,862 : INFO : EPOCH 19 - PROGRESS: at 69.46% examples, 346043 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:34,874 : INFO : EPOCH 19 - PROGRESS: at 92.31% examples, 367917 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:35,171 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-02 07:09:35,181 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-02 07:09:35,186 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-02 07:09:35,186 : INFO : EPOCH - 19 : training on 3151036 raw words (2017294 effective words) took 5.4s, 375290 effective words/s\n",
      "2019-01-02 07:09:36,220 : INFO : EPOCH 20 - PROGRESS: at 15.51% examples, 305263 words/s, in_qsize 4, out_qsize 1\n",
      "2019-01-02 07:09:37,231 : INFO : EPOCH 20 - PROGRESS: at 27.88% examples, 276276 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:38,247 : INFO : EPOCH 20 - PROGRESS: at 50.76% examples, 335261 words/s, in_qsize 6, out_qsize 0\n",
      "2019-01-02 07:09:39,269 : INFO : EPOCH 20 - PROGRESS: at 73.87% examples, 365960 words/s, in_qsize 4, out_qsize 1\n",
      "2019-01-02 07:09:40,283 : INFO : EPOCH 20 - PROGRESS: at 92.31% examples, 365995 words/s, in_qsize 5, out_qsize 0\n",
      "2019-01-02 07:09:40,673 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-01-02 07:09:40,681 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-01-02 07:09:40,681 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-01-02 07:09:40,681 : INFO : EPOCH - 20 : training on 3151036 raw words (2017841 effective words) took 5.5s, 367602 effective words/s\n",
      "2019-01-02 07:09:40,681 : INFO : training on a 63020720 raw words (40346730 effective words) took 107.5s, 375348 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size 25806\r\n"
     ]
    }
   ],
   "source": [
    "!kpython3 code/fasttext.py \"synthesized train data\" \"synthesized test data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,000 sentences embedded.\n",
      "20,000 sentences embedded.\n",
      "30,000 sentences embedded.\n",
      "40,000 sentences embedded.\n",
      "50,000 sentences embedded.\n",
      "60,000 sentences embedded.\n",
      "70,000 sentences embedded.\n",
      "80,000 sentences embedded.\n",
      "90,000 sentences embedded.\n",
      "100,000 sentences embedded.\n",
      "110,000 sentences embedded.\n",
      "120,000 sentences embedded.\n",
      "130,000 sentences embedded.\n",
      "140,000 sentences embedded.\n",
      "150,000 sentences embedded.\n",
      "160,000 sentences embedded.\n",
      "170,000 sentences embedded.\n",
      "180,000 sentences embedded.\n",
      "190,000 sentences embedded.\n",
      "200,000 sentences embedded.\n",
      "210,000 sentences embedded.\n",
      "220,000 sentences embedded.\n",
      "230,000 sentences embedded.\n",
      "240,000 sentences embedded.\n",
      "250,000 sentences embedded.\n",
      "260,000 sentences embedded.\n",
      "270,000 sentences embedded.\n",
      "280,000 sentences embedded.\n",
      "290,000 sentences embedded.\n",
      "300,000 sentences embedded.\n",
      "310,000 sentences embedded.\n",
      "320,000 sentences embedded.\n",
      "330,000 sentences embedded.\n",
      "340,000 sentences embedded.\n",
      "350,000 sentences embedded.\n",
      "360,000 sentences embedded.\n",
      "370,000 sentences embedded.\n",
      "380,000 sentences embedded.\n",
      "390,000 sentences embedded.\n",
      "2019-01-02 07:21:43.073614: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2019-01-02 07:21:43.225704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:17:00.0\n",
      "totalMemory: 10.92GiB freeMemory: 3.68GiB\n",
      "2019-01-02 07:21:43.346067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 10.92GiB freeMemory: 8.33GiB\n",
      "2019-01-02 07:21:43.346964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1\n",
      "2019-01-02 07:21:44.437400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-01-02 07:21:44.437445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 \n",
      "2019-01-02 07:21:44.437455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y \n",
      "2019-01-02 07:21:44.437464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N \n",
      "2019-01-02 07:21:44.437789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3404 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "2019-01-02 07:21:44.438186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 8045 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 64)           6598688     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "man_dist (ManDist)              (None, 1)            0           sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "==================================================================================================\n",
      "Total params: 6,598,688\n",
      "Trainable params: 146,688\n",
      "Non-trainable params: 6,452,000\n",
      "__________________________________________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 250)           6452000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 20, 64)            80640     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 20, 64)            33024     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                33024     \n",
      "=================================================================\n",
      "Total params: 6,598,688\n",
      "Trainable params: 146,688\n",
      "Non-trainable params: 6,452,000\n",
      "_________________________________________________________________\n",
      "Train on 379050 samples, validate on 19950 samples\n",
      "Epoch 1/3\n",
      "379050/379050 [==============================] - 137s 361us/step - loss: 0.0485 - acc: 0.9540 - val_loss: 0.0288 - val_acc: 0.9738\n",
      "Epoch 2/3\n",
      "379050/379050 [==============================] - 132s 349us/step - loss: 0.0263 - acc: 0.9739 - val_loss: 0.0244 - val_acc: 0.9759\n",
      "Epoch 3/3\n",
      "379050/379050 [==============================] - 132s 347us/step - loss: 0.0226 - acc: 0.9764 - val_loss: 0.0211 - val_acc: 0.9774\n",
      "19950/19950 [==============================] - 3s 138us/step\n",
      "loss,accuracy [0.021052518398839429, 0.97744360869988467]\n",
      "[[9522  377]\n",
      " [  73 9978]]\n",
      "recall 0.99273704109\n",
      "precision 0.963592467407\n",
      "log loss 0.102505\n",
      "log loss 0.730633\n",
      "Training time finished.\n",
      "3 epochs in       450.78\n",
      "0.9774(max: 0.9774)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "!kpython3 code/train.py 1 \"synthesized train data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,000 sentences embedded.\n",
      "(19950,)\n",
      "(19950, 20) (19950, 20)\n",
      "2019-01-02 07:30:29.545934: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2019-01-02 07:30:29.731323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:17:00.0\n",
      "totalMemory: 10.92GiB freeMemory: 3.68GiB\n",
      "2019-01-02 07:30:29.848789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 10.92GiB freeMemory: 8.33GiB\n",
      "2019-01-02 07:30:29.849865: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1\n",
      "2019-01-02 07:30:30.745432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-01-02 07:30:30.745473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 \n",
      "2019-01-02 07:30:30.745482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y \n",
      "2019-01-02 07:30:30.745492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N \n",
      "2019-01-02 07:30:30.745729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3404 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "2019-01-02 07:30:30.746054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 8045 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 64)           6598688     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "man_dist (ManDist)              (None, 1)            0           sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "==================================================================================================\n",
      "Total params: 6,598,688\n",
      "Trainable params: 146,688\n",
      "Non-trainable params: 6,452,000\n",
      "__________________________________________________________________________________________________\n",
      "19950/19950 [==============================] - 3s 170us/step\n",
      "loss,accuracy [0.021052518398839429, 0.97744360869988467]\n",
      "[[9522  377]\n",
      " [  73 9978]]\n",
      "recall 0.99273704109\n",
      "precision 0.963592467407\n",
      "log loss 0.102505\n",
      "log loss 0.730633\n"
     ]
    }
   ],
   "source": [
    "!kpython3 code/evaluate.py 1 \"valid_split\"  # valid data\n",
    "!kpython3 code/evaluate.py 1 \"test\" # test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0   id                                          question1  \\\r\n",
      "0             0    0                                               city   \r\n",
      "1             1    1                                               city   \r\n",
      "2             2    2                                               city   \r\n",
      "3             3    3                                               city   \r\n",
      "4             4    4                                               city   \r\n",
      "5             5    5                        the state in which you work   \r\n",
      "6             6    6                        the state in which you work   \r\n",
      "7             7    7                        the state in which you work   \r\n",
      "8             8    8                        the state in which you work   \r\n",
      "9             9    9                        the state in which you work   \r\n",
      "10           10   10  date of visit for this current condition(s)(mm...   \r\n",
      "11           11   11  date of visit for this current condition(s)(mm...   \r\n",
      "12           12   12  date of visit for this current condition(s)(mm...   \r\n",
      "13           13   13  date of visit for this current condition(s)(mm...   \r\n",
      "14           14   14  date of visit for this current condition(s)(mm...   \r\n",
      "15           15   15                          physician's tax id number   \r\n",
      "16           16   16                          physician's tax id number   \r\n",
      "17           17   17                          physician's tax id number   \r\n",
      "18           18   18                          physician's tax id number   \r\n",
      "19           19   19                          physician's tax id number   \r\n",
      "20           20   20               date of next office visit (mm/dd/yy)   \r\n",
      "21           21   21               date of next office visit (mm/dd/yy)   \r\n",
      "22           22   22               date of next office visit (mm/dd/yy)   \r\n",
      "23           23   23               date of next office visit (mm/dd/yy)   \r\n",
      "24           24   24               date of next office visit (mm/dd/yy)   \r\n",
      "25           25   25                                           zip code   \r\n",
      "26           26   26                                           zip code   \r\n",
      "27           27   27                                           zip code   \r\n",
      "28           28   28                                           zip code   \r\n",
      "29           29   29                                           zip code   \r\n",
      "..          ...  ...                                                ...   \r\n",
      "95           95   95  preferred e-mail address (for confirmation pur...   \r\n",
      "96           96   96  preferred e-mail address (for confirmation pur...   \r\n",
      "97           97   97  preferred e-mail address (for confirmation pur...   \r\n",
      "98           98   98  preferred e-mail address (for confirmation pur...   \r\n",
      "99           99   99  preferred e-mail address (for confirmation pur...   \r\n",
      "100         100  100                                  diagnosis remarks   \r\n",
      "101         101  101                                  diagnosis remarks   \r\n",
      "102         102  102                                  diagnosis remarks   \r\n",
      "103         103  103                                  diagnosis remarks   \r\n",
      "104         104  104                                  diagnosis remarks   \r\n",
      "105         105  105                                         diagnosis:   \r\n",
      "106         106  106                                         diagnosis:   \r\n",
      "107         107  107                                         diagnosis:   \r\n",
      "108         108  108                                         diagnosis:   \r\n",
      "109         109  109                                         diagnosis:   \r\n",
      "110         110  110                                    patient gender:   \r\n",
      "111         111  111                                    patient gender:   \r\n",
      "112         112  112                                    patient gender:   \r\n",
      "113         113  113                                    patient gender:   \r\n",
      "114         114  114                                    patient gender:   \r\n",
      "115         115  115                                      tax id or ssn   \r\n",
      "116         116  116                                      tax id or ssn   \r\n",
      "117         117  117                                      tax id or ssn   \r\n",
      "118         118  118                                      tax id or ssn   \r\n",
      "119         119  119                                      tax id or ssn   \r\n",
      "120         120  120                                            fax no.   \r\n",
      "121         121  121                                            fax no.   \r\n",
      "122         122  122                                            fax no.   \r\n",
      "123         123  123                                            fax no.   \r\n",
      "124         124  124                                            fax no.   \r\n",
      "\r\n",
      "                                             question2  is_duplicate  \r\n",
      "0                                          south elgin             1  \r\n",
      "1                                                   no             0  \r\n",
      "2                                          505-22-0585             0  \r\n",
      "3                                       (617)-024-5585             0  \r\n",
      "4                                          Amber Walls             0  \r\n",
      "5                                                   NE             1  \r\n",
      "6                                       (770)-450-5764             0  \r\n",
      "7                                                  yes             0  \r\n",
      "8                                         884 372-1383             0  \r\n",
      "9                                                28637             0  \r\n",
      "10                                            01-19-94             1  \r\n",
      "11                                                  NM             0  \r\n",
      "12                                             S72.332             0  \r\n",
      "13                                               29246             0  \r\n",
      "14                                        123 033 8763             0  \r\n",
      "15                                           624728500             1  \r\n",
      "16                AVERA HEART HOSPITAL OF SOUTH DAKOTA             0  \r\n",
      "17                                         456-38-5338             0  \r\n",
      "18                                      (581)-525-2057             0  \r\n",
      "19                                               82449             0  \r\n",
      "20                                            12/25/89             1  \r\n",
      "21                                     Travis Phillips             0  \r\n",
      "22                                          75-7618804             0  \r\n",
      "23                                     Virginia Rivera             0  \r\n",
      "24                                      (212) 702 5620             0  \r\n",
      "25                                               39089             1  \r\n",
      "26                                      Brett Mckinney             0  \r\n",
      "27                                         399-49-3888             0  \r\n",
      "28                                         386-54-6900             0  \r\n",
      "29                                         125 30 5235             0  \r\n",
      "..                                                 ...           ...  \r\n",
      "95                                           yahoo.com             1  \r\n",
      "96                                                  MD             0  \r\n",
      "97                                                  no             0  \r\n",
      "98                                          38-2847624             0  \r\n",
      "99                                               24609             0  \r\n",
      "100  Adverse effect of mixed antiepileptics, subseq...             1  \r\n",
      "101                                             female             0  \r\n",
      "102                                                  i             0  \r\n",
      "103                                         88-9009134             0  \r\n",
      "104                                      207 N High St             0  \r\n",
      "105  Poisoning by other drugs acting on muscles, ac...             1  \r\n",
      "106                                  sgibson@james.biz             0  \r\n",
      "107                                        717-18-2312             0  \r\n",
      "108                                        173-89-7943             0  \r\n",
      "109                                         barrington             0  \r\n",
      "110                                             female             1  \r\n",
      "111                                      21-23 Jane St             0  \r\n",
      "112                                                 MO             0  \r\n",
      "113                                     Erika Robinson             0  \r\n",
      "114                                        John Holder             0  \r\n",
      "115                                        697-88-0763             1  \r\n",
      "116                      Syphilis of lung and bronchus             0  \r\n",
      "117                                         98-3885218             0  \r\n",
      "118                                         86-0323982             0  \r\n",
      "119                       mendozakatherine@example.org             0  \r\n",
      "120                                       531-825-7344             1  \r\n",
      "121                                     new kensington             0  \r\n",
      "122                                       481 432-0205             0  \r\n",
      "123                                       Chad Skinner             0  \r\n",
      "124                                     (528)-558-7915             0  \r\n",
      "\r\n",
      "[125 rows x 5 columns]\r\n",
      "original dataframe size (125, 5)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125,)\n",
      "(125, 20) (125, 20)\n",
      "2019-01-02 07:33:12.271092: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2019-01-02 07:33:12.428907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:17:00.0\n",
      "totalMemory: 10.92GiB freeMemory: 3.68GiB\n",
      "2019-01-02 07:33:12.554398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 10.92GiB freeMemory: 8.33GiB\n",
      "2019-01-02 07:33:12.555266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1\n",
      "2019-01-02 07:33:13.455933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-01-02 07:33:13.455972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 \n",
      "2019-01-02 07:33:13.455987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y \n",
      "2019-01-02 07:33:13.455993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N \n",
      "2019-01-02 07:33:13.456227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3404 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "2019-01-02 07:33:13.456538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 8045 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 64)           6598688     input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "man_dist (ManDist)              (None, 1)            0           sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "==================================================================================================\n",
      "Total params: 6,598,688\n",
      "Trainable params: 146,688\n",
      "Non-trainable params: 6,452,000\n",
      "__________________________________________________________________________________________________\n",
      "125/125 [==============================] - 1s 7ms/step\n",
      "[0.027594238519668579, 0.96799999475479126]\n",
      "city >>> south elgin \n",
      " south elgin:0.917849\n",
      "Amber Walls:0.172096\n",
      "no:0.060171\n",
      "505-22-0585:0.010625\n",
      "(617)-024-5585:0.00127403\n",
      "the state in which you work >>> NE \n",
      " NE:0.874619\n",
      "28637:0.0521585\n",
      "yes:0.0290777\n",
      "(770)-450-5764:0.00192236\n",
      "884 372-1383:0.00185024\n",
      "date of visit for this current condition(s)(mm/dd/yy) >>> 01-19-94 \n",
      " 01-19-94:0.915983\n",
      "S72.332:0.0139504\n",
      "123 033 8763:0.0090156\n",
      "29246:0.00865221\n",
      "NM:0.00466599\n",
      "physician's tax id number >>> 624728500 \n",
      " 82449:0.814382\n",
      "624728500:0.814382\n",
      "456-38-5338:0.0436248\n",
      "(581)-525-2057:0.0232051\n",
      "AVERA HEART HOSPITAL OF SOUTH DAKOTA:0.000459575\n",
      "date of next office visit (mm/dd/yy) >>> 12/25/89 \n",
      " 12/25/89:0.963284\n",
      "Travis Phillips:0.0239713\n",
      "Virginia Rivera:0.0229796\n",
      "(212) 702 5620:0.00923335\n",
      "75-7618804:0.00755021\n",
      "zip code >>> 39089 \n",
      " 39089:0.956429\n",
      "125 30 5235:0.100743\n",
      "399-49-3888:0.0507296\n",
      "386-54-6900:0.0499445\n",
      "Brett Mckinney:0.00588025\n",
      "please include primary icd-9 or dsm-iv multi-axial diagnosis codes >>> S62.353 \n",
      " S62.353:0.983728\n",
      "Oth physl fx lower end of l tibia, subs for fx w delay heal:0.0495565\n",
      "648-69-6784:0.0377533\n",
      "276-343 1079:0.00774522\n",
      "BAPTIST HEALTH LA GRANGE:0.00261177\n",
      "are you currently self-employed? >>> yes \n",
      " yes:0.962945\n",
      "f:0.0519837\n",
      "7400 Fightin Hollar:0.00210849\n",
      "653 42 9431:0.00172437\n",
      "058-41-2508:0.00166667\n",
      "provider name >>> Frank Villanueva \n",
      " Frank Villanueva:0.938193\n",
      "Unsp intracap fx unsp femr, 7thH:0.126212\n",
      "t:0.02785\n",
      "S72.422:0.0217915\n",
      "04944:0.00624015\n",
      "diagnosis/icd-9 code >>> S72.052 \n",
      " S72.052:0.973011\n",
      "57857:0.162068\n",
      "95689:0.162068\n",
      "12/17/1990:0.0131443\n",
      "06/30/83:0.0129\n",
      "email address >>> mariehuerta@gmail.com \n",
      " mariehuerta@gmail.com:0.971472\n",
      "271238710:0.0288921\n",
      "21 Washington Road:0.00460983\n",
      "Kimberly Hughes:0.00460388\n",
      "124 482-4063:0.00296021\n",
      "gender >>> male \n",
      " male:0.950889\n",
      "K29.3:0.0852088\n",
      "yes:0.0505447\n",
      "230-04-1837:0.00366021\n",
      "5711 Buckhead Dr:0.000752307\n",
      "diagnosis remarks >>> Crushing injury of head, part unspecified, subsequent encounter \n",
      " Crushing injury of head, part unspecified, subsequent encounter:0.939987\n",
      "09 19 01:0.0719881\n",
      "04-14-2005:0.0696257\n",
      "no:0.0175366\n",
      "(436) 020-5115:0.00158694\n",
      "insured social security number >>> 330-86-9487 \n",
      " 330-86-9487:0.957506\n",
      "238-772-7385:0.0935299\n",
      "David Phillips:0.008523\n",
      "r:0.00544674\n",
      "CHANDLER REGIONAL MEDICAL CENTER:0.00370699\n",
      "social security number >>> 072 83 8097 \n",
      " 072 83 8097:0.904193\n",
      "(802) 048-6849:0.0977501\n",
      "S42.451:0.0371684\n",
      "ME:0.00645602\n",
      "VT:0.00518948\n",
      "state >>> AL \n",
      " AL:0.937028\n",
      "bedford:0.0953444\n",
      "yes:0.0273279\n",
      "no:0.0267328\n",
      "no:0.0267328\n",
      "social security number >>> 047-67-3051 \n",
      " 047-67-3051:0.935249\n",
      "92757:0.0484469\n",
      "69-3624060:0.0422861\n",
      "NE:0.00641704\n",
      "female:0.00353945\n",
      "fax no. >>> 832-453 1467 \n",
      " 832-453 1467:0.890208\n",
      "(416)-234-3717:0.836319\n",
      "69841:0.0261139\n",
      "26824:0.0261139\n",
      "aurora:0.00128923\n",
      "name of patient (if not self) >>> Robert Ramos \n",
      " Robert Ramos:0.947893\n",
      "yes:0.0889503\n",
      "MOUNTAINS COMMUNITY HOSPITAL:0.0234508\n",
      "female:0.0233571\n",
      "96368:0.00646715\n",
      "preferred e-mail address (for confirmation purposes only) >>> yahoo.com \n",
      " yahoo.com:0.983368\n",
      "24609:0.0288672\n",
      "38-2847624:0.0230466\n",
      "MD:0.00933142\n",
      "no:0.000673435\n",
      "diagnosis remarks >>> Adverse effect of mixed antiepileptics, subsequent encounter \n",
      " Adverse effect of mixed antiepileptics, subsequent encounter:0.939047\n",
      "i:0.02756\n",
      "female:0.0202939\n",
      "88-9009134:0.0153932\n",
      "207 N High St:0.000489552\n",
      "diagnosis: >>> Poisoning by other drugs acting on muscles, accidental (unintentional), initial encounter \n",
      " Poisoning by other drugs acting on muscles, accidental (unintentional), initial encounter:0.946237\n",
      "barrington:0.175329\n",
      "sgibson@james.biz:0.0335643\n",
      "173-89-7943:0.0150838\n",
      "717-18-2312:0.0148409\n",
      "patient gender: >>> female \n",
      " female:0.922587\n",
      "MO:0.474904\n",
      "Erika Robinson:0.0195424\n",
      "John Holder:0.01702\n",
      "21-23 Jane St:0.00143259\n",
      "tax id or ssn >>> 697-88-0763 \n",
      " 697-88-0763:0.931598\n",
      "86-0323982:0.0433346\n",
      "98-3885218:0.0419186\n",
      "mendozakatherine@example.org:0.0214471\n",
      "Syphilis of lung and bronchus:0.0139325\n",
      "fax no. >>> 531-825-7344 \n",
      " 481 432-0205:0.861294\n",
      "531-825-7344:0.854079\n",
      "(528)-558-7915:0.852259\n",
      "new kensington:0.00133616\n",
      "Chad Skinner:0.000985646\n"
     ]
    }
   ],
   "source": [
    "# live demo\n",
    "!kpython3 code/demo.py 1 \"synthesized demo data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-29 04:20:55.853162: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2018-12-29 04:20:56.022729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:17:00.0\n",
      "totalMemory: 10.92GiB freeMemory: 10.76GiB\n",
      "2018-12-29 04:20:56.177916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 10.92GiB freeMemory: 10.56GiB\n",
      "2018-12-29 04:20:56.179488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1\n",
      "2018-12-29 04:20:56.833595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2018-12-29 04:20:56.833643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 \n",
      "2018-12-29 04:20:56.833653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N Y \n",
      "2018-12-29 04:20:56.833660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   Y N \n",
      "2018-12-29 04:20:56.834018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10405 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "2018-12-29 04:20:56.838520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10212 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1)\n"
     ]
    }
   ],
   "source": [
    "# comment uncomment one by one\n",
    "#!kpython3 code/fasttext.py \"train\" \"test\"\n",
    "#!kpython3 code/train.py 1 \"train\"\n",
    "#!kpython3 code/evaluate.py 1 \"valid_split\" \n",
    "#!kpython3 code/evaluate.py 1 \"test\" \n",
    "#!kpython3 code/demo.py 1 \"demo\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
