{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gpu tests.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "hVaU4L4c4y-4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "\n",
        "!mkdir models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lwhKDolv49Vg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "upload **train.csv/test.csv/demo.csv/sanity.csv** to data\n",
        "\n",
        "upload **train.py/predict.py/demo.py/util.py/fasttext.py**  to the local directory\n",
        "\n",
        "models will be saved to **models**  directory"
      ]
    },
    {
      "metadata": {
        "id": "Xnf2d00WBdhD",
        "colab_type": "code",
        "outputId": "5c887058-a212-4183-802e-95452906b24f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "TkM3fEq5BL9P",
        "colab_type": "code",
        "outputId": "f10557dd-9a09-4978-f88c-3b623d11b7ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2247
        }
      },
      "cell_type": "code",
      "source": [
        "!python3 fasttext.py"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-12-26 09:50:44,635 : INFO : read 1000 sentences\n",
            "2018-12-26 09:50:44,763 : INFO : read 2000 sentences\n",
            "2018-12-26 09:50:44,891 : INFO : read 3000 sentences\n",
            "2018-12-26 09:50:45,021 : INFO : read 4000 sentences\n",
            "2018-12-26 09:50:45,150 : INFO : read 5000 sentences\n",
            "2018-12-26 09:50:45,281 : INFO : read 6000 sentences\n",
            "2018-12-26 09:50:45,412 : INFO : read 7000 sentences\n",
            "2018-12-26 09:50:45,541 : INFO : read 8000 sentences\n",
            "2018-12-26 09:50:45,669 : INFO : read 9000 sentences\n",
            "2018-12-26 09:50:45,798 : INFO : read 10000 sentences\n",
            "2018-12-26 09:50:45,929 : INFO : read 11000 sentences\n",
            "2018-12-26 09:50:46,058 : INFO : read 12000 sentences\n",
            "2018-12-26 09:50:46,186 : INFO : read 13000 sentences\n",
            "2018-12-26 09:50:46,324 : INFO : read 14000 sentences\n",
            "2018-12-26 09:50:46,461 : INFO : read 15000 sentences\n",
            "2018-12-26 09:50:46,593 : INFO : read 16000 sentences\n",
            "2018-12-26 09:50:46,721 : INFO : read 17000 sentences\n",
            "2018-12-26 09:50:46,856 : INFO : read 18000 sentences\n",
            "2018-12-26 09:50:46,998 : INFO : read 19000 sentences\n",
            "2018-12-26 09:50:47,128 : INFO : read 20000 sentences\n",
            "2018-12-26 09:50:47,262 : INFO : read 21000 sentences\n",
            "2018-12-26 09:50:47,395 : INFO : read 22000 sentences\n",
            "2018-12-26 09:50:47,523 : INFO : read 23000 sentences\n",
            "2018-12-26 09:50:47,657 : INFO : read 24000 sentences\n",
            "2018-12-26 09:50:47,794 : INFO : read 25000 sentences\n",
            "2018-12-26 09:50:47,930 : INFO : read 26000 sentences\n",
            "2018-12-26 09:50:48,063 : INFO : read 27000 sentences\n",
            "2018-12-26 09:50:48,196 : INFO : read 28000 sentences\n",
            "2018-12-26 09:50:48,329 : INFO : read 29000 sentences\n",
            "2018-12-26 09:50:48,464 : INFO : read 30000 sentences\n",
            "2018-12-26 09:50:48,598 : INFO : read 31000 sentences\n",
            "2018-12-26 09:50:48,729 : INFO : read 32000 sentences\n",
            "2018-12-26 09:50:48,864 : INFO : read 33000 sentences\n",
            "2018-12-26 09:50:49,002 : INFO : read 34000 sentences\n",
            "2018-12-26 09:50:49,132 : INFO : read 35000 sentences\n",
            "2018-12-26 09:50:49,267 : INFO : read 36000 sentences\n",
            "2018-12-26 09:50:49,404 : INFO : read 37000 sentences\n",
            "2018-12-26 09:50:49,533 : INFO : read 38000 sentences\n",
            "2018-12-26 09:50:49,662 : INFO : read 39000 sentences\n",
            "2018-12-26 09:50:49,798 : INFO : read 40000 sentences\n",
            "2018-12-26 09:50:49,927 : INFO : read 41000 sentences\n",
            "2018-12-26 09:50:50,063 : INFO : read 42000 sentences\n",
            "2018-12-26 09:50:50,196 : INFO : read 43000 sentences\n",
            "2018-12-26 09:50:50,328 : INFO : read 44000 sentences\n",
            "2018-12-26 09:50:50,459 : INFO : read 45000 sentences\n",
            "2018-12-26 09:50:50,594 : INFO : read 46000 sentences\n",
            "2018-12-26 09:50:50,725 : INFO : read 47000 sentences\n",
            "2018-12-26 09:50:50,854 : INFO : read 48000 sentences\n",
            "2018-12-26 09:50:50,994 : INFO : read 49000 sentences\n",
            "2018-12-26 09:50:51,150 : INFO : Done reading data file\n",
            "2018-12-26 09:50:51,150 : INFO : collecting all words and their counts\n",
            "2018-12-26 09:50:51,150 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2018-12-26 09:50:51,162 : INFO : PROGRESS: at sentence #10000, processed 42614 words, keeping 584 word types\n",
            "2018-12-26 09:50:51,174 : INFO : PROGRESS: at sentence #20000, processed 86003 words, keeping 584 word types\n",
            "2018-12-26 09:50:51,186 : INFO : PROGRESS: at sentence #30000, processed 128153 words, keeping 584 word types\n",
            "2018-12-26 09:50:51,198 : INFO : PROGRESS: at sentence #40000, processed 170614 words, keeping 584 word types\n",
            "2018-12-26 09:50:51,210 : INFO : PROGRESS: at sentence #50000, processed 213029 words, keeping 584 word types\n",
            "2018-12-26 09:50:51,223 : INFO : PROGRESS: at sentence #60000, processed 255879 words, keeping 584 word types\n",
            "2018-12-26 09:50:51,235 : INFO : PROGRESS: at sentence #70000, processed 298049 words, keeping 584 word types\n",
            "2018-12-26 09:50:51,247 : INFO : PROGRESS: at sentence #80000, processed 340236 words, keeping 584 word types\n",
            "2018-12-26 09:50:51,253 : INFO : collected 584 word types from a corpus of 357442 raw words and 84463 sentences\n",
            "2018-12-26 09:50:51,253 : INFO : Loading a fresh vocabulary\n",
            "2018-12-26 09:50:51,254 : INFO : effective_min_count=5 retains 584 unique words (100% of original 584, drops 0)\n",
            "2018-12-26 09:50:51,254 : INFO : effective_min_count=5 leaves 357442 word corpus (100% of original 357442, drops 0)\n",
            "2018-12-26 09:50:51,256 : INFO : deleting the raw counts dictionary of 584 items\n",
            "2018-12-26 09:50:51,257 : INFO : sample=0.001 downsamples 69 most-common words\n",
            "2018-12-26 09:50:51,257 : INFO : downsampling leaves estimated 188881 word corpus (52.8% of prior 357442)\n",
            "2018-12-26 09:50:51,265 : INFO : estimated required memory for 584 words, 6838 buckets and 300 dimensions: 10012136 bytes\n",
            "2018-12-26 09:50:51,265 : INFO : resetting layer weights\n",
            "tcmalloc: large alloc 2400002048 bytes == 0x3e66000 @  0x7fc393e341e7 0x7fc390acca41 0x7fc390b2fc13 0x7fc390b3199e 0x7fc390bc9748 0x5030d5 0x507641 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x501b2e 0x591461 0x59ebbe 0x507c17 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x501b2e 0x591461\n",
            "tcmalloc: large alloc 2400002048 bytes == 0x92f38000 @  0x7fc393e341e7 0x7fc390acca41 0x7fc390b2fc13 0x7fc390b3199e 0x7fc390bc9748 0x5030d5 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x501b2e 0x591461 0x59ebbe 0x507c17 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d\n",
            "2018-12-26 09:50:52,716 : INFO : Total number of ngrams is 6838\n",
            "2018-12-26 09:50:52,886 : INFO : training model with 3 workers on 584 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2018-12-26 09:50:53,922 : INFO : EPOCH 1 - PROGRESS: at 72.14% examples, 133082 words/s, in_qsize 5, out_qsize 0\n",
            "2018-12-26 09:50:54,175 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-12-26 09:50:54,203 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-12-26 09:50:54,221 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-12-26 09:50:54,221 : INFO : EPOCH - 1 : training on 357442 raw words (188772 effective words) took 1.3s, 142079 effective words/s\n",
            "2018-12-26 09:50:55,234 : INFO : EPOCH 2 - PROGRESS: at 72.14% examples, 136227 words/s, in_qsize 5, out_qsize 0\n",
            "2018-12-26 09:50:55,482 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-12-26 09:50:55,523 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-12-26 09:50:55,531 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-12-26 09:50:55,531 : INFO : EPOCH - 2 : training on 357442 raw words (188843 effective words) took 1.3s, 144886 effective words/s\n",
            "2018-12-26 09:50:56,559 : INFO : EPOCH 3 - PROGRESS: at 72.14% examples, 134260 words/s, in_qsize 5, out_qsize 0\n",
            "2018-12-26 09:50:56,812 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-12-26 09:50:56,826 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-12-26 09:50:56,838 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-12-26 09:50:56,838 : INFO : EPOCH - 3 : training on 357442 raw words (188745 effective words) took 1.3s, 145156 effective words/s\n",
            "2018-12-26 09:50:57,881 : INFO : EPOCH 4 - PROGRESS: at 72.19% examples, 134220 words/s, in_qsize 5, out_qsize 0\n",
            "2018-12-26 09:50:58,112 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-12-26 09:50:58,141 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-12-26 09:50:58,146 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-12-26 09:50:58,146 : INFO : EPOCH - 4 : training on 357442 raw words (189055 effective words) took 1.3s, 146651 effective words/s\n",
            "2018-12-26 09:50:59,194 : INFO : EPOCH 5 - PROGRESS: at 74.98% examples, 137605 words/s, in_qsize 5, out_qsize 0\n",
            "2018-12-26 09:50:59,405 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-12-26 09:50:59,460 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-12-26 09:50:59,463 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-12-26 09:50:59,463 : INFO : EPOCH - 5 : training on 357442 raw words (189246 effective words) took 1.3s, 145040 effective words/s\n",
            "2018-12-26 09:51:00,491 : INFO : EPOCH 6 - PROGRESS: at 72.14% examples, 134698 words/s, in_qsize 5, out_qsize 0\n",
            "2018-12-26 09:51:00,762 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-12-26 09:51:00,772 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-12-26 09:51:00,780 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-12-26 09:51:00,780 : INFO : EPOCH - 6 : training on 357442 raw words (189116 effective words) took 1.3s, 144457 effective words/s\n",
            "2018-12-26 09:51:01,850 : INFO : EPOCH 7 - PROGRESS: at 74.93% examples, 134201 words/s, in_qsize 5, out_qsize 0\n",
            "2018-12-26 09:51:02,066 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-12-26 09:51:02,068 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-12-26 09:51:02,088 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-12-26 09:51:02,088 : INFO : EPOCH - 7 : training on 357442 raw words (189004 effective words) took 1.3s, 145367 effective words/s\n",
            "2018-12-26 09:51:03,111 : INFO : EPOCH 8 - PROGRESS: at 72.14% examples, 134963 words/s, in_qsize 5, out_qsize 0\n",
            "2018-12-26 09:51:03,375 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-12-26 09:51:03,375 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-12-26 09:51:03,409 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-12-26 09:51:03,409 : INFO : EPOCH - 8 : training on 357442 raw words (188566 effective words) took 1.3s, 143630 effective words/s\n",
            "2018-12-26 09:51:04,485 : INFO : EPOCH 9 - PROGRESS: at 74.93% examples, 133434 words/s, in_qsize 4, out_qsize 1\n",
            "2018-12-26 09:51:04,679 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-12-26 09:51:04,704 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-12-26 09:51:04,713 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-12-26 09:51:04,713 : INFO : EPOCH - 9 : training on 357442 raw words (189131 effective words) took 1.3s, 145714 effective words/s\n",
            "2018-12-26 09:51:05,748 : INFO : EPOCH 10 - PROGRESS: at 72.20% examples, 133875 words/s, in_qsize 5, out_qsize 0\n",
            "2018-12-26 09:51:05,984 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2018-12-26 09:51:06,019 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2018-12-26 09:51:06,025 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2018-12-26 09:51:06,025 : INFO : EPOCH - 10 : training on 357442 raw words (189277 effective words) took 1.3s, 145292 effective words/s\n",
            "2018-12-26 09:51:06,025 : INFO : training on a 3574420 raw words (1889755 effective words) took 13.1s, 143824 effective words/s\n",
            "2018-12-26 09:51:06,055 : INFO : saving FastText object under ./models/Quora-Question-Pairs.ft, separately None\n",
            "2018-12-26 09:51:06,056 : INFO : not storing attribute vectors_norm\n",
            "2018-12-26 09:51:06,056 : INFO : not storing attribute vectors_vocab_norm\n",
            "2018-12-26 09:51:06,056 : INFO : not storing attribute vectors_ngrams_norm\n",
            "2018-12-26 09:51:06,056 : INFO : not storing attribute buckets_word\n",
            "2018-12-26 09:51:06,292 : INFO : saved ./models/Quora-Question-Pairs.ft\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "faXXzN7dBQu8",
        "colab_type": "code",
        "outputId": "97c39fbd-b158-44ee-9106-e9e30fd9919c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2247
        }
      },
      "cell_type": "code",
      "source": [
        "!python train.py 0 train"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading fasttext model(it may takes 2-3 mins) ...\n",
            "1,000 sentences embedded.\n",
            "2,000 sentences embedded.\n",
            "3,000 sentences embedded.\n",
            "4,000 sentences embedded.\n",
            "5,000 sentences embedded.\n",
            "6,000 sentences embedded.\n",
            "7,000 sentences embedded.\n",
            "8,000 sentences embedded.\n",
            "9,000 sentences embedded.\n",
            "10,000 sentences embedded.\n",
            "11,000 sentences embedded.\n",
            "12,000 sentences embedded.\n",
            "13,000 sentences embedded.\n",
            "14,000 sentences embedded.\n",
            "15,000 sentences embedded.\n",
            "16,000 sentences embedded.\n",
            "17,000 sentences embedded.\n",
            "18,000 sentences embedded.\n",
            "19,000 sentences embedded.\n",
            "20,000 sentences embedded.\n",
            "21,000 sentences embedded.\n",
            "22,000 sentences embedded.\n",
            "23,000 sentences embedded.\n",
            "24,000 sentences embedded.\n",
            "25,000 sentences embedded.\n",
            "26,000 sentences embedded.\n",
            "27,000 sentences embedded.\n",
            "28,000 sentences embedded.\n",
            "29,000 sentences embedded.\n",
            "30,000 sentences embedded.\n",
            "31,000 sentences embedded.\n",
            "32,000 sentences embedded.\n",
            "33,000 sentences embedded.\n",
            "34,000 sentences embedded.\n",
            "35,000 sentences embedded.\n",
            "36,000 sentences embedded.\n",
            "37,000 sentences embedded.\n",
            "38,000 sentences embedded.\n",
            "39,000 sentences embedded.\n",
            "40,000 sentences embedded.\n",
            "41,000 sentences embedded.\n",
            "42,000 sentences embedded.\n",
            "43,000 sentences embedded.\n",
            "44,000 sentences embedded.\n",
            "45,000 sentences embedded.\n",
            "46,000 sentences embedded.\n",
            "47,000 sentences embedded.\n",
            "48,000 sentences embedded.\n",
            "49,000 sentences embedded.\n",
            "2018-12-26 09:51:24.598624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-12-26 09:51:24.599109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-12-26 09:51:24.599152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-12-26 09:51:24.997292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-12-26 09:51:24.997366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-12-26 09:51:24.997389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-12-26 09:51:24.997698: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2018-12-26 09:51:24.997773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 64)           368888      input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "man_dist (ManDist)              (None, 1)            0           sequential[1][0]                 \n",
            "                                                                 sequential[2][0]                 \n",
            "==================================================================================================\n",
            "Total params: 368,888\n",
            "Trainable params: 159,488\n",
            "Non-trainable params: 209,400\n",
            "__________________________________________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 20, 300)           209400    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 20, 64)            93440     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 20, 64)            33024     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 64)                33024     \n",
            "=================================================================\n",
            "Total params: 368,888\n",
            "Trainable params: 159,488\n",
            "Non-trainable params: 209,400\n",
            "_________________________________________________________________\n",
            "Train on 47046 samples, validate on 2476 samples\n",
            "Epoch 1/10\n",
            "47046/47046 [==============================] - 37s 792us/step - loss: 0.2212 - acc: 0.6480 - val_loss: 0.1838 - val_acc: 0.7391\n",
            "Epoch 2/10\n",
            "47046/47046 [==============================] - 34s 713us/step - loss: 0.1677 - acc: 0.7612 - val_loss: 0.1575 - val_acc: 0.7799\n",
            "Epoch 3/10\n",
            "47046/47046 [==============================] - 34s 716us/step - loss: 0.1472 - acc: 0.7977 - val_loss: 0.1419 - val_acc: 0.8078\n",
            "Epoch 4/10\n",
            "47046/47046 [==============================] - 34s 713us/step - loss: 0.1349 - acc: 0.8219 - val_loss: 0.1353 - val_acc: 0.8215\n",
            "Epoch 5/10\n",
            "47046/47046 [==============================] - 34s 714us/step - loss: 0.1272 - acc: 0.8353 - val_loss: 0.1301 - val_acc: 0.8300\n",
            "Epoch 6/10\n",
            "47046/47046 [==============================] - 33s 705us/step - loss: 0.1211 - acc: 0.8440 - val_loss: 0.1241 - val_acc: 0.8384\n",
            "Epoch 7/10\n",
            "47046/47046 [==============================] - 33s 712us/step - loss: 0.1175 - acc: 0.8486 - val_loss: 0.1232 - val_acc: 0.8389\n",
            "Epoch 8/10\n",
            "47046/47046 [==============================] - 34s 715us/step - loss: 0.1157 - acc: 0.8511 - val_loss: 0.1214 - val_acc: 0.8409\n",
            "Epoch 9/10\n",
            "47046/47046 [==============================] - 34s 713us/step - loss: 0.1135 - acc: 0.8558 - val_loss: 0.1200 - val_acc: 0.8473\n",
            "Epoch 10/10\n",
            "47046/47046 [==============================] - 34s 714us/step - loss: 0.1115 - acc: 0.8561 - val_loss: 0.1176 - val_acc: 0.8469\n",
            "2476/2476 [==============================] - 1s 272us/step\n",
            "loss,accuracy [0.11760541392258565, 0.8469305316735547]\n",
            "[[23551  4061]\n",
            " [ 2560 16874]]\n",
            "recall 0.8682721004425235\n",
            "precision 0.8060186290900406\n",
            "log loss 0.3826287\n",
            "[[1214  239]\n",
            " [ 140  883]]\n",
            "recall 0.863147605083089\n",
            "precision 0.7869875222816399\n",
            "log loss 0.42067277\n",
            "Training time finished.\n",
            "10 epochs in       546.40\n",
            "0.8469(max: 0.8473)\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TLGRgrKgBi21",
        "colab_type": "code",
        "outputId": "c57c87c7-cae9-4e91-fd9f-2a5826064b9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "cell_type": "code",
      "source": [
        "!python3 predict.py 0 sanity"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading fasttext model(it may takes 2-3 mins) ...\n",
            "(35,)\n",
            "(35, 20) (35, 20)\n",
            "2018-12-26 10:02:53.745845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-12-26 10:02:53.746353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-12-26 10:02:53.746437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-12-26 10:02:54.146280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-12-26 10:02:54.146371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-12-26 10:02:54.146412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-12-26 10:02:54.146765: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2018-12-26 10:02:54.146870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 64)           368888      input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "man_dist (ManDist)              (None, 1)            0           sequential[1][0]                 \n",
            "                                                                 sequential[2][0]                 \n",
            "==================================================================================================\n",
            "Total params: 368,888\n",
            "Trainable params: 159,488\n",
            "Non-trainable params: 209,400\n",
            "__________________________________________________________________________________________________\n",
            "35/35 [==============================] - 1s 26ms/step\n",
            "loss,accuracy [0.1900990903377533, 0.6857143044471741]\n",
            "[[24  4]\n",
            " [ 7  0]]\n",
            "recall 0.0\n",
            "precision 0.0\n",
            "log loss 0.61239576\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pxccG7rABnNr",
        "colab_type": "code",
        "outputId": "ce21637a-1653-4b6c-b9d4-cea325811779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1465
        }
      },
      "cell_type": "code",
      "source": [
        "!python3 demo.py 0 sanity"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    id        question1           question2  is_duplicate\n",
            "0    0        Employer:   SMITH, HEIDI , J.             1\n",
            "1    1        Employer:              864053             0\n",
            "2    2        Employer:         491 22 7531             0\n",
            "3    3        Employer:            08-15-47             0\n",
            "4    4        Employer:              461568             0\n",
            "5    5  Group Policy #:              864053             1\n",
            "6    6  Group Policy #:   SMITH, HEIDI , J.             0\n",
            "7    7  Group Policy #:         491 22 7531             0\n",
            "8    8  Group Policy #:            08-15-47             0\n",
            "9    9  Group Policy #:              461568             0\n",
            "10  10      Customer #:              461568             1\n",
            "11  11      Customer #:         491 22 7531             0\n",
            "12  12      Customer #:            08-15-47             0\n",
            "13  13      Customer #:              864053             0\n",
            "14  14      Customer #:            04-26-74             0\n",
            "15  15            SS #:         491 22 7531             1\n",
            "16  16            SS #:            08-15-47             0\n",
            "17  17            SS #:              864053             0\n",
            "18  18            SS #:   SMITH, HEIDI , J.             0\n",
            "19  19            SS #:              461568             0\n",
            "20  20         EE Name:  ROSEN , ALBERT , K             1\n",
            "21  21         EE Name:         491 22 7531             0\n",
            "22  22         EE Name:            08-15-47             0\n",
            "23  23         EE Name:              461568             0\n",
            "24  24         EE Name:            04-26-74             0\n",
            "25  25          EE DOB:            08-15-47             1\n",
            "26  26          EE DOB:         491 22 7531             0\n",
            "27  27          EE DOB:            04-26-74             0\n",
            "28  28          EE DOB:              461568             0\n",
            "29  29          EE DOB:  ROSEN , ALBERT , K             0\n",
            "30  30       Spouse DOB            04-26-74             1\n",
            "31  31       Spouse DOB            08-15-47             0\n",
            "32  32       Spouse DOB         491 22 7531             0\n",
            "33  33       Spouse DOB              461568             0\n",
            "34  34       Spouse DOB  ROSEN , ALBERT , K             0\n",
            "original dataframe size (35, 4)\n",
            "Loading fasttext model(it may takes 2-3 mins) ...\n",
            "(35,)\n",
            "(35, 20) (35, 20)\n",
            "2018-12-26 10:03:10.691629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-12-26 10:03:10.692112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2018-12-26 10:03:10.692157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\n",
            "2018-12-26 10:03:11.097673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-12-26 10:03:11.097754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \n",
            "2018-12-26 10:03:11.097787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \n",
            "2018-12-26 10:03:11.098081: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2018-12-26 10:03:11.098147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, 64)           368888      input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "man_dist (ManDist)              (None, 1)            0           sequential[1][0]                 \n",
            "                                                                 sequential[2][0]                 \n",
            "==================================================================================================\n",
            "Total params: 368,888\n",
            "Trainable params: 159,488\n",
            "Non-trainable params: 209,400\n",
            "__________________________________________________________________________________________________\n",
            "35/35 [==============================] - 1s 26ms/step\n",
            "[0.1900990903377533, 0.6857143044471741]\n",
            "(5, 1)\n",
            "field: Employer: [predicted: ['SMITH, HEIDI , J.', '461568', '491 22 7531', '864053', '08-15-47'] ||| actual: SMITH, HEIDI , J. ]\n",
            "(5, 1)\n",
            "field: Group Policy #: [predicted: ['461568', '491 22 7531', 'SMITH, HEIDI , J.', '864053', '08-15-47'] ||| actual: 864053 ]\n",
            "(5, 1)\n",
            "field: Customer #: [predicted: ['461568', '491 22 7531', '864053', '04-26-74', '08-15-47'] ||| actual: 461568 ]\n",
            "(5, 1)\n",
            "field: SS #: [predicted: ['SMITH, HEIDI , J.', '461568', '491 22 7531', '864053', '08-15-47'] ||| actual: 491 22 7531 ]\n",
            "(5, 1)\n",
            "field: EE Name: [predicted: ['491 22 7531', '461568', '04-26-74', 'ROSEN , ALBERT , K', '08-15-47'] ||| actual: ROSEN , ALBERT , K ]\n",
            "(5, 1)\n",
            "field: EE DOB: [predicted: ['491 22 7531', '461568', 'ROSEN , ALBERT , K', '04-26-74', '08-15-47'] ||| actual: 08-15-47 ]\n",
            "(5, 1)\n",
            "field: Spouse DOB [predicted: ['ROSEN , ALBERT , K', '04-26-74', '491 22 7531', '461568', '08-15-47'] ||| actual: 04-26-74 ]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}